{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iy41lO4JEsu1"
      },
      "outputs": [],
      "source": [
        "#import the relevant libraries\n",
        "from google.colab import files\n",
        "import pandas\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import io\n",
        "from tensorflow.keras.models import Sequential \n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.utils import *\n",
        "from sklearn.model_selection import KFold\n",
        "from mpl_toolkits import mplot3d\n",
        "from keras.optimizers import Adam\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.regularizers import l2\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Kirsch's Solution for hoop stress\n",
        "def sigt(sigref, a, r, theta):\n",
        "  sigmatheta = 0.5*sigref*(1+(a/r)**2) - 0.5*sigref*(1+3*(a/r)**4)*np.cos(2*theta*np.pi/180)\n",
        "  return sigmatheta"
      ],
      "metadata": {
        "id": "01fIgCPzFIa5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#generate the x values along y = 0\n",
        "xp = np.linspace(0,100,30)\n",
        "#radius varying between 10 and 60\n",
        "a = np.linspace(10,60,6)\n",
        "#theta at 90 to get hoop stress along y=0\n",
        "theta = 90\n",
        "#reference (remote) stress of 1\n",
        "sigref = 1"
      ],
      "metadata": {
        "id": "xyC1j_ggFMDj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#The ANN accepts x as the only input parameter\n",
        "fig, ax = plt.subplots()\n",
        "fig1, ax1 = plt.subplots()\n",
        "etime = []\n",
        "loss = []\n",
        "#looping through each value of a for simplicity\n",
        "for i in a:\n",
        "  #create empty lists to store the calculated values\n",
        "  x1p = []\n",
        "  sig = []\n",
        "  for j in xp:\n",
        "    if abs(j) > i:\n",
        "      #the ratio a/w, the radius to the length/2\n",
        "      awp = i/100\n",
        "      #apply the equation, and then scale using the ratio above, to capture higher stress concentration for larger holes\n",
        "      sigthetap = sigt(sigref, i, j, theta)/(1-awp)\n",
        "      #visualize the stress along x\n",
        "      ax.scatter(j, sigthetap, label=\"radius \"+str(i))\n",
        "      plt.ylabel(\"Hoop Stress\")\n",
        "      plt.xlabel(\"X\")\n",
        "      plt.title(\"Actual Hoop Stress with X\")\n",
        "      plt.legend()\n",
        "      x1p.append(j)\n",
        "      sig.append(sigthetap)\n",
        "\n",
        "  # Set up a sequential neural network\n",
        "  scaler = StandardScaler()\n",
        "\n",
        "\n",
        "  model = Sequential()\n",
        "\n",
        "  # Scale the training data\n",
        "  # train the data on x, for each value of a\n",
        "  x1p_normalized = (x1p - np.mean(x1p)) / np.std(x1p)\n",
        "  sig_normalized = (sig - np.mean(sig)) / np.std(sig)\n",
        "\n",
        "  # First split the data into a training set and a temporary set.\n",
        "  x1p_train, x1p_temp, sig_train, sig_temp = train_test_split(x1p_normalized, sig_normalized, test_size=0.3)\n",
        "\n",
        "  # Then split the temp_set into a validation set and a testing set.\n",
        "  x1p_val, x1p_test, sig_val, sig_test = train_test_split(x1p_temp, sig_temp, test_size=0.5)\n",
        "\n",
        "\n",
        "  # # Add L2 regularization and dropout for the hidden layers\n",
        "  # model.add(Dense(units=3, activation='gelu', input_dim=1, kernel_regularizer=l2(0.01)))\n",
        "  # model.add(Dropout(0.2))\n",
        "  # model.add(Dense(units=6, activation='gelu', kernel_regularizer=l2(0.01)))\n",
        "  # model.add(Dropout(0.2))\n",
        "  # model.add(Dense(units=6, activation='gelu', kernel_regularizer=l2(0.01)))\n",
        "  # model.add(Dropout(0.2))\n",
        "  # model.add(Dense(units=6, activation='gelu', kernel_regularizer=l2(0.01)))\n",
        "  # model.add(Dropout(0.2))\n",
        "\n",
        "  # model.add(Dense(units=1, activation='softplus'))\n",
        "  # Add a layer of 3 nodes of GeLUs, taking two input parameters\n",
        "  model.add(Dense(units=3, activation='gelu', input_dim=1))\n",
        "\n",
        "  # Add a linear node at the end to combine the nodes together\n",
        "  model.add(Dense(units=6, activation='gelu'))\n",
        "\n",
        "  # Add a linear node at the end to combine the nodes together\n",
        "  model.add(Dense(units=6, activation='gelu'))\n",
        "\n",
        "  # Add a linear node at the end to combine the nodes together\n",
        "  model.add(Dense(units=6, activation='gelu'))\n",
        "\n",
        "\n",
        "  # Add the final output layer with the 'softplus' activation function\n",
        "  model.add(Dense(units=1, activation='softplus'))\n",
        "\n",
        "  #learning rate\n",
        "  optimizer = Adam(lr=0.001)\n",
        "\n",
        "  # Compile the model\n",
        "  model.compile(loss=\"mean_squared_error\", optimizer=optimizer)\n",
        "\n",
        "  start_time = time.time()\n",
        "\n",
        "  # Fit the data \n",
        "  # Include validation data\n",
        "  history = model.fit(x1p_train, sig_train, epochs=400, batch_size=12, validation_data=(x1p_val, sig_val))\n",
        "\n",
        "  end_time = time.time()\n",
        "\n",
        "  # Calculate execution time\n",
        "  execution_time = end_time - start_time\n",
        "  etime.append(execution_time)\n",
        "\n",
        "  # Evaluate the model on the test set\n",
        "  test_loss = model.evaluate(x1p_test, sig_test, verbose=0)\n",
        "  loss.append(test_loss)\n",
        "\n",
        "  #plot all the testing data on one curve\n",
        "  xtest = np.linspace(i,100,50)\n",
        "  xtest_normalized = (xtest - np.mean(x1p)) / np.std(x1p)\n",
        "\n",
        "  y_pred_normalized = model.predict(xtest_normalized)\n",
        "  y_pred = y_pred_normalized * np.std(sig) + np.mean(sig)\n",
        "  ax1.scatter(xtest, y_pred, label=\"radius \"+str(i))\n",
        "  plt.ylabel(\"Hoop Stress\")\n",
        "  plt.xlabel(\"X\")\n",
        "  plt.title(\"Predicted Hoop Stress with X\")\n",
        "  plt.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "c1hTo-pfYLIl",
        "outputId": "e678a48f-dc5f-435c-a322-9e23c8e7262e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "/usr/local/lib/python3.10/dist-packages/keras/optimizers/legacy/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "2/2 [==============================] - 2s 448ms/step - loss: 1.7249 - val_loss: 0.9687\n",
            "Epoch 2/400\n",
            "2/2 [==============================] - 0s 98ms/step - loss: 1.7202 - val_loss: 0.9650\n",
            "Epoch 3/400\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 1.7165 - val_loss: 0.9613\n",
            "Epoch 4/400\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 1.7123 - val_loss: 0.9578\n",
            "Epoch 5/400\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 1.7082 - val_loss: 0.9543\n",
            "Epoch 6/400\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 1.7040 - val_loss: 0.9508\n",
            "Epoch 7/400\n",
            "2/2 [==============================] - 0s 92ms/step - loss: 1.7002 - val_loss: 0.9474\n",
            "Epoch 8/400\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 1.6961 - val_loss: 0.9439\n",
            "Epoch 9/400\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 1.6931 - val_loss: 0.9405\n",
            "Epoch 10/400\n",
            "2/2 [==============================] - 0s 94ms/step - loss: 1.6885 - val_loss: 0.9372\n",
            "Epoch 11/400\n",
            "2/2 [==============================] - 0s 101ms/step - loss: 1.6849 - val_loss: 0.9339\n",
            "Epoch 12/400\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 1.6810 - val_loss: 0.9306\n",
            "Epoch 13/400\n",
            "2/2 [==============================] - 0s 101ms/step - loss: 1.6773 - val_loss: 0.9273\n",
            "Epoch 14/400\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 1.6736 - val_loss: 0.9240\n",
            "Epoch 15/400\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 1.6699 - val_loss: 0.9207\n",
            "Epoch 16/400\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 1.6661 - val_loss: 0.9174\n",
            "Epoch 17/400\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 1.6624 - val_loss: 0.9141\n",
            "Epoch 18/400\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 1.6586 - val_loss: 0.9109\n",
            "Epoch 19/400\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 1.6550 - val_loss: 0.9077\n",
            "Epoch 20/400\n",
            "2/2 [==============================] - 0s 101ms/step - loss: 1.6511 - val_loss: 0.9045\n",
            "Epoch 21/400\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 1.6475 - val_loss: 0.9012\n",
            "Epoch 22/400\n",
            "2/2 [==============================] - 0s 121ms/step - loss: 1.6444 - val_loss: 0.8980\n",
            "Epoch 23/400\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 1.6407 - val_loss: 0.8949\n",
            "Epoch 24/400\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 1.6368 - val_loss: 0.8918\n",
            "Epoch 25/400\n",
            "2/2 [==============================] - 0s 75ms/step - loss: 1.6333 - val_loss: 0.8887\n",
            "Epoch 26/400\n",
            "2/2 [==============================] - 0s 74ms/step - loss: 1.6301 - val_loss: 0.8857\n",
            "Epoch 27/400\n",
            "2/2 [==============================] - 0s 82ms/step - loss: 1.6264 - val_loss: 0.8826\n",
            "Epoch 28/400\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 1.6227 - val_loss: 0.8796\n",
            "Epoch 29/400\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 1.6199 - val_loss: 0.8766\n",
            "Epoch 30/400\n",
            "2/2 [==============================] - 0s 94ms/step - loss: 1.6158 - val_loss: 0.8736\n",
            "Epoch 31/400\n",
            "2/2 [==============================] - 0s 121ms/step - loss: 1.6123 - val_loss: 0.8705\n",
            "Epoch 32/400\n",
            "2/2 [==============================] - 0s 191ms/step - loss: 1.6090 - val_loss: 0.8674\n",
            "Epoch 33/400\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 1.6055 - val_loss: 0.8643\n",
            "Epoch 34/400\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 1.6018 - val_loss: 0.8612\n",
            "Epoch 35/400\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 1.5983 - val_loss: 0.8581\n",
            "Epoch 36/400\n",
            "2/2 [==============================] - 0s 147ms/step - loss: 1.5946 - val_loss: 0.8549\n",
            "Epoch 37/400\n",
            "2/2 [==============================] - 0s 98ms/step - loss: 1.5910 - val_loss: 0.8518\n",
            "Epoch 38/400\n",
            "2/2 [==============================] - 0s 205ms/step - loss: 1.5879 - val_loss: 0.8486\n",
            "Epoch 39/400\n",
            "2/2 [==============================] - 0s 156ms/step - loss: 1.5838 - val_loss: 0.8454\n",
            "Epoch 40/400\n",
            "2/2 [==============================] - 0s 114ms/step - loss: 1.5803 - val_loss: 0.8423\n",
            "Epoch 41/400\n",
            "2/2 [==============================] - 0s 131ms/step - loss: 1.5770 - val_loss: 0.8392\n",
            "Epoch 42/400\n",
            "2/2 [==============================] - 0s 115ms/step - loss: 1.5730 - val_loss: 0.8361\n",
            "Epoch 43/400\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 1.5698 - val_loss: 0.8329\n",
            "Epoch 44/400\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 1.5658 - val_loss: 0.8298\n",
            "Epoch 45/400\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 1.5629 - val_loss: 0.8266\n",
            "Epoch 46/400\n",
            "2/2 [==============================] - 0s 135ms/step - loss: 1.5587 - val_loss: 0.8234\n",
            "Epoch 47/400\n",
            "2/2 [==============================] - 0s 117ms/step - loss: 1.5552 - val_loss: 0.8202\n",
            "Epoch 48/400\n",
            "2/2 [==============================] - 0s 137ms/step - loss: 1.5515 - val_loss: 0.8169\n",
            "Epoch 49/400\n",
            "2/2 [==============================] - 0s 143ms/step - loss: 1.5478 - val_loss: 0.8137\n",
            "Epoch 50/400\n",
            "2/2 [==============================] - 0s 106ms/step - loss: 1.5444 - val_loss: 0.8104\n",
            "Epoch 51/400\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 1.5404 - val_loss: 0.8070\n",
            "Epoch 52/400\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 1.5368 - val_loss: 0.8036\n",
            "Epoch 53/400\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 1.5329 - val_loss: 0.8002\n",
            "Epoch 54/400\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 1.5292 - val_loss: 0.7967\n",
            "Epoch 55/400\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 1.5252 - val_loss: 0.7932\n",
            "Epoch 56/400\n",
            "2/2 [==============================] - 0s 75ms/step - loss: 1.5210 - val_loss: 0.7896\n",
            "Epoch 57/400\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 1.5170 - val_loss: 0.7859\n",
            "Epoch 58/400\n",
            "2/2 [==============================] - 0s 90ms/step - loss: 1.5130 - val_loss: 0.7822\n",
            "Epoch 59/400\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 1.5088 - val_loss: 0.7784\n",
            "Epoch 60/400\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 1.5046 - val_loss: 0.7746\n",
            "Epoch 61/400\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 1.5003 - val_loss: 0.7708\n",
            "Epoch 62/400\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 1.4959 - val_loss: 0.7667\n",
            "Epoch 63/400\n",
            "2/2 [==============================] - 0s 120ms/step - loss: 1.4911 - val_loss: 0.7625\n",
            "Epoch 64/400\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 1.4865 - val_loss: 0.7580\n",
            "Epoch 65/400\n",
            "2/2 [==============================] - 0s 92ms/step - loss: 1.4812 - val_loss: 0.7533\n",
            "Epoch 66/400\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 1.4769 - val_loss: 0.7482\n",
            "Epoch 67/400\n",
            "2/2 [==============================] - 0s 82ms/step - loss: 1.4715 - val_loss: 0.7431\n",
            "Epoch 68/400\n",
            "2/2 [==============================] - 0s 117ms/step - loss: 1.4659 - val_loss: 0.7378\n",
            "Epoch 69/400\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 1.4600 - val_loss: 0.7325\n",
            "Epoch 70/400\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 1.4541 - val_loss: 0.7270\n",
            "Epoch 71/400\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 1.4470 - val_loss: 0.7214\n",
            "Epoch 72/400\n",
            "2/2 [==============================] - 0s 131ms/step - loss: 1.4400 - val_loss: 0.7151\n",
            "Epoch 73/400\n",
            "2/2 [==============================] - 0s 91ms/step - loss: 1.4349 - val_loss: 0.7078\n",
            "Epoch 74/400\n",
            "2/2 [==============================] - 0s 123ms/step - loss: 1.4272 - val_loss: 0.7005\n",
            "Epoch 75/400\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 1.4188 - val_loss: 0.6929\n",
            "Epoch 76/400\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 1.4105 - val_loss: 0.6851\n",
            "Epoch 77/400\n",
            "2/2 [==============================] - 0s 77ms/step - loss: 1.4014 - val_loss: 0.6770\n",
            "Epoch 78/400\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 1.3924 - val_loss: 0.6685\n",
            "Epoch 79/400\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 1.3825 - val_loss: 0.6596\n",
            "Epoch 80/400\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 1.3725 - val_loss: 0.6502\n",
            "Epoch 81/400\n",
            "2/2 [==============================] - 0s 92ms/step - loss: 1.3579 - val_loss: 0.6408\n",
            "Epoch 82/400\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 1.3448 - val_loss: 0.6294\n",
            "Epoch 83/400\n",
            "2/2 [==============================] - 0s 99ms/step - loss: 1.3365 - val_loss: 0.6160\n",
            "Epoch 84/400\n",
            "2/2 [==============================] - 0s 99ms/step - loss: 1.3212 - val_loss: 0.6024\n",
            "Epoch 85/400\n",
            "2/2 [==============================] - 0s 117ms/step - loss: 1.3036 - val_loss: 0.5888\n",
            "Epoch 86/400\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 1.2863 - val_loss: 0.5749\n",
            "Epoch 87/400\n",
            "2/2 [==============================] - 0s 125ms/step - loss: 1.2693 - val_loss: 0.5609\n",
            "Epoch 88/400\n",
            "2/2 [==============================] - 0s 153ms/step - loss: 1.2418 - val_loss: 0.5477\n",
            "Epoch 89/400\n",
            "2/2 [==============================] - 0s 98ms/step - loss: 1.2329 - val_loss: 0.5320\n",
            "Epoch 90/400\n",
            "2/2 [==============================] - 0s 94ms/step - loss: 1.2088 - val_loss: 0.5173\n",
            "Epoch 91/400\n",
            "2/2 [==============================] - 0s 148ms/step - loss: 1.1758 - val_loss: 0.5038\n",
            "Epoch 92/400\n",
            "2/2 [==============================] - 0s 177ms/step - loss: 1.1661 - val_loss: 0.4892\n",
            "Epoch 93/400\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 1.1403 - val_loss: 0.4766\n",
            "Epoch 94/400\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 1.1183 - val_loss: 0.4661\n",
            "Epoch 95/400\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 1.0925 - val_loss: 0.4578\n",
            "Epoch 96/400\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 1.0724 - val_loss: 0.4512\n",
            "Epoch 97/400\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 1.0425 - val_loss: 0.4464\n",
            "Epoch 98/400\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 1.0217 - val_loss: 0.4444\n",
            "Epoch 99/400\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 1.0012 - val_loss: 0.4470\n",
            "Epoch 100/400\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.9943 - val_loss: 0.4553\n",
            "Epoch 101/400\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.9681 - val_loss: 0.4661\n",
            "Epoch 102/400\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.9712 - val_loss: 0.4797\n",
            "Epoch 103/400\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.9444 - val_loss: 0.4870\n",
            "Epoch 104/400\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.9323 - val_loss: 0.4994\n",
            "Epoch 105/400\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.9337 - val_loss: 0.5167\n",
            "Epoch 106/400\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.9245 - val_loss: 0.5260\n",
            "Epoch 107/400\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.9167 - val_loss: 0.5267\n",
            "Epoch 108/400\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 0.9033 - val_loss: 0.5170\n",
            "Epoch 109/400\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.8920 - val_loss: 0.5020\n",
            "Epoch 110/400\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.8789 - val_loss: 0.4866\n",
            "Epoch 111/400\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.8662 - val_loss: 0.4709\n",
            "Epoch 112/400\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.8540 - val_loss: 0.4516\n",
            "Epoch 113/400\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.8438 - val_loss: 0.4332\n",
            "Epoch 114/400\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.8345 - val_loss: 0.4169\n",
            "Epoch 115/400\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.8284 - val_loss: 0.4024\n",
            "Epoch 116/400\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.8216 - val_loss: 0.3914\n",
            "Epoch 117/400\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.8178 - val_loss: 0.3832\n",
            "Epoch 118/400\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.8081 - val_loss: 0.3807\n",
            "Epoch 119/400\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.8007 - val_loss: 0.3828\n",
            "Epoch 120/400\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.7884 - val_loss: 0.3837\n",
            "Epoch 121/400\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.7770 - val_loss: 0.3850\n",
            "Epoch 122/400\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.7650 - val_loss: 0.3923\n",
            "Epoch 123/400\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.7590 - val_loss: 0.4051\n",
            "Epoch 124/400\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.7513 - val_loss: 0.4154\n",
            "Epoch 125/400\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.7361 - val_loss: 0.4195\n",
            "Epoch 126/400\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.7269 - val_loss: 0.4260\n",
            "Epoch 127/400\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.7229 - val_loss: 0.4354\n",
            "Epoch 128/400\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.7110 - val_loss: 0.4381\n",
            "Epoch 129/400\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.7010 - val_loss: 0.4460\n",
            "Epoch 130/400\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.6995 - val_loss: 0.4552\n",
            "Epoch 131/400\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.6883 - val_loss: 0.4512\n",
            "Epoch 132/400\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.6784 - val_loss: 0.4378\n",
            "Epoch 133/400\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.6676 - val_loss: 0.4249\n",
            "Epoch 134/400\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.6587 - val_loss: 0.4087\n",
            "Epoch 135/400\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.6497 - val_loss: 0.3909\n",
            "Epoch 136/400\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.6513 - val_loss: 0.3735\n",
            "Epoch 137/400\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.6382 - val_loss: 0.3687\n",
            "Epoch 138/400\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.6307 - val_loss: 0.3622\n",
            "Epoch 139/400\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.6298 - val_loss: 0.3541\n",
            "Epoch 140/400\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.6197 - val_loss: 0.3578\n",
            "Epoch 141/400\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.6110 - val_loss: 0.3581\n",
            "Epoch 142/400\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.6053 - val_loss: 0.3568\n",
            "Epoch 143/400\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.5967 - val_loss: 0.3662\n",
            "Epoch 144/400\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.5902 - val_loss: 0.3737\n",
            "Epoch 145/400\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.5797 - val_loss: 0.3762\n",
            "Epoch 146/400\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.5715 - val_loss: 0.3855\n",
            "Epoch 147/400\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.5636 - val_loss: 0.4006\n",
            "Epoch 148/400\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.5600 - val_loss: 0.4225\n",
            "Epoch 149/400\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.5505 - val_loss: 0.4381\n",
            "Epoch 150/400\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.5469 - val_loss: 0.4545\n",
            "Epoch 151/400\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.5462 - val_loss: 0.4627\n",
            "Epoch 152/400\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.5346 - val_loss: 0.4495\n",
            "Epoch 153/400\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.5260 - val_loss: 0.4271\n",
            "Epoch 154/400\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.5179 - val_loss: 0.4046\n",
            "Epoch 155/400\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.5123 - val_loss: 0.3824\n",
            "Epoch 156/400\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.5105 - val_loss: 0.3664\n",
            "Epoch 157/400\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.5017 - val_loss: 0.3636\n",
            "Epoch 158/400\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.4980 - val_loss: 0.3576\n",
            "Epoch 159/400\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.4899 - val_loss: 0.3650\n",
            "Epoch 160/400\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.4836 - val_loss: 0.3848\n",
            "Epoch 161/400\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.4769 - val_loss: 0.4025\n",
            "Epoch 162/400\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.4719 - val_loss: 0.4160\n",
            "Epoch 163/400\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.4687 - val_loss: 0.4206\n",
            "Epoch 164/400\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.4604 - val_loss: 0.4094\n",
            "Epoch 165/400\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.4544 - val_loss: 0.3881\n",
            "Epoch 166/400\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.4488 - val_loss: 0.3712\n",
            "Epoch 167/400\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.4494 - val_loss: 0.3592\n",
            "Epoch 168/400\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.4414 - val_loss: 0.3632\n",
            "Epoch 169/400\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.4354 - val_loss: 0.3609\n",
            "Epoch 170/400\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.4297 - val_loss: 0.3529\n",
            "Epoch 171/400\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.4249 - val_loss: 0.3412\n",
            "Epoch 172/400\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.4234 - val_loss: 0.3324\n",
            "Epoch 173/400\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.4179 - val_loss: 0.3362\n",
            "Epoch 174/400\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.4126 - val_loss: 0.3423\n",
            "Epoch 175/400\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.4079 - val_loss: 0.3509\n",
            "Epoch 176/400\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.4053 - val_loss: 0.3747\n",
            "Epoch 177/400\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.3954 - val_loss: 0.3895\n",
            "Epoch 178/400\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.3927 - val_loss: 0.4168\n",
            "Epoch 179/400\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.3860 - val_loss: 0.4342\n",
            "Epoch 180/400\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.3823 - val_loss: 0.4480\n",
            "Epoch 181/400\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.3797 - val_loss: 0.4665\n",
            "Epoch 182/400\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.3763 - val_loss: 0.4754\n",
            "Epoch 183/400\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.3712 - val_loss: 0.4924\n",
            "Epoch 184/400\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.3731 - val_loss: 0.5106\n",
            "Epoch 185/400\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.3663 - val_loss: 0.4997\n",
            "Epoch 186/400\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.3643 - val_loss: 0.4781\n",
            "Epoch 187/400\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.3548 - val_loss: 0.4688\n",
            "Epoch 188/400\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.3492 - val_loss: 0.4552\n",
            "Epoch 189/400\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.3450 - val_loss: 0.4349\n",
            "Epoch 190/400\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.3415 - val_loss: 0.4213\n",
            "Epoch 191/400\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.3366 - val_loss: 0.4208\n",
            "Epoch 192/400\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.3313 - val_loss: 0.4331\n",
            "Epoch 193/400\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.3279 - val_loss: 0.4411\n",
            "Epoch 194/400\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.3242 - val_loss: 0.4590\n",
            "Epoch 195/400\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.3213 - val_loss: 0.4686\n",
            "Epoch 196/400\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.3182 - val_loss: 0.4675\n",
            "Epoch 197/400\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.3139 - val_loss: 0.4531\n",
            "Epoch 198/400\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.3090 - val_loss: 0.4291\n",
            "Epoch 199/400\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.3050 - val_loss: 0.3962\n",
            "Epoch 200/400\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.3069 - val_loss: 0.3712\n",
            "Epoch 201/400\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.2991 - val_loss: 0.3684\n",
            "Epoch 202/400\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.2960 - val_loss: 0.3601\n",
            "Epoch 203/400\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.2925 - val_loss: 0.3639\n",
            "Epoch 204/400\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.2892 - val_loss: 0.3685\n",
            "Epoch 205/400\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.2872 - val_loss: 0.3700\n",
            "Epoch 206/400\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.2824 - val_loss: 0.3604\n",
            "Epoch 207/400\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.2828 - val_loss: 0.3552\n",
            "Epoch 208/400\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.2773 - val_loss: 0.3707\n",
            "Epoch 209/400\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.2754 - val_loss: 0.3835\n",
            "Epoch 210/400\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.2703 - val_loss: 0.3838\n",
            "Epoch 211/400\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.2674 - val_loss: 0.3848\n",
            "Epoch 212/400\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.2665 - val_loss: 0.3840\n",
            "Epoch 213/400\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.2620 - val_loss: 0.4013\n",
            "Epoch 214/400\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.2591 - val_loss: 0.4143\n",
            "Epoch 215/400\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.2569 - val_loss: 0.4229\n",
            "Epoch 216/400\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.2556 - val_loss: 0.4206\n",
            "Epoch 217/400\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.2513 - val_loss: 0.3993\n",
            "Epoch 218/400\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.2482 - val_loss: 0.3807\n",
            "Epoch 219/400\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.2463 - val_loss: 0.3636\n",
            "Epoch 220/400\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.2443 - val_loss: 0.3518\n",
            "Epoch 221/400\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.2416 - val_loss: 0.3329\n",
            "Epoch 222/400\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.2407 - val_loss: 0.3136\n",
            "Epoch 223/400\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.2403 - val_loss: 0.3022\n",
            "Epoch 224/400\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.2394 - val_loss: 0.2977\n",
            "Epoch 225/400\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.2402 - val_loss: 0.3005\n",
            "Epoch 226/400\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.2332 - val_loss: 0.3292\n",
            "Epoch 227/400\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.2270 - val_loss: 0.3794\n",
            "Epoch 228/400\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.2259 - val_loss: 0.4357\n",
            "Epoch 229/400\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.2277 - val_loss: 0.4784\n",
            "Epoch 230/400\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.2260 - val_loss: 0.4882\n",
            "Epoch 231/400\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.2216 - val_loss: 0.4675\n",
            "Epoch 232/400\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.2184 - val_loss: 0.4380\n",
            "Epoch 233/400\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.2183 - val_loss: 0.4124\n",
            "Epoch 234/400\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.2139 - val_loss: 0.4071\n",
            "Epoch 235/400\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.2101 - val_loss: 0.4173\n",
            "Epoch 236/400\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.2088 - val_loss: 0.4226\n",
            "Epoch 237/400\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.2063 - val_loss: 0.4396\n",
            "Epoch 238/400\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.2069 - val_loss: 0.4467\n",
            "Epoch 239/400\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.2032 - val_loss: 0.4272\n",
            "Epoch 240/400\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.2007 - val_loss: 0.4066\n",
            "Epoch 241/400\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.2008 - val_loss: 0.3899\n",
            "Epoch 242/400\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.1965 - val_loss: 0.3920\n",
            "Epoch 243/400\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.1948 - val_loss: 0.3929\n",
            "Epoch 244/400\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.1930 - val_loss: 0.3892\n",
            "Epoch 245/400\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.1913 - val_loss: 0.3833\n",
            "Epoch 246/400\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.1895 - val_loss: 0.3833\n",
            "Epoch 247/400\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.1889 - val_loss: 0.3883\n",
            "Epoch 248/400\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.1890 - val_loss: 0.4074\n",
            "Epoch 249/400\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.1854 - val_loss: 0.4025\n",
            "Epoch 250/400\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.1829 - val_loss: 0.3833\n",
            "Epoch 251/400\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.1814 - val_loss: 0.3650\n",
            "Epoch 252/400\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.1820 - val_loss: 0.3541\n",
            "Epoch 253/400\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.1788 - val_loss: 0.3640\n",
            "Epoch 254/400\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.1770 - val_loss: 0.3708\n",
            "Epoch 255/400\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.1754 - val_loss: 0.3765\n",
            "Epoch 256/400\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.1740 - val_loss: 0.3804\n",
            "Epoch 257/400\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.1732 - val_loss: 0.3794\n",
            "Epoch 258/400\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.1711 - val_loss: 0.3659\n",
            "Epoch 259/400\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.1720 - val_loss: 0.3551\n",
            "Epoch 260/400\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.1689 - val_loss: 0.3652\n",
            "Epoch 261/400\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.1674 - val_loss: 0.3747\n",
            "Epoch 262/400\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.1670 - val_loss: 0.3811\n",
            "Epoch 263/400\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.1647 - val_loss: 0.3740\n",
            "Epoch 264/400\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.1636 - val_loss: 0.3713\n",
            "Epoch 265/400\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.1627 - val_loss: 0.3660\n",
            "Epoch 266/400\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.1609 - val_loss: 0.3504\n",
            "Epoch 267/400\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.1628 - val_loss: 0.3320\n",
            "Epoch 268/400\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.1595 - val_loss: 0.3380\n",
            "Epoch 269/400\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.1581 - val_loss: 0.3466\n",
            "Epoch 270/400\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.1579 - val_loss: 0.3551\n",
            "Epoch 271/400\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.1554 - val_loss: 0.3502\n",
            "Epoch 272/400\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.1546 - val_loss: 0.3448\n",
            "Epoch 273/400\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.1533 - val_loss: 0.3319\n",
            "Epoch 274/400\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.1526 - val_loss: 0.3158\n",
            "Epoch 275/400\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.1544 - val_loss: 0.3089\n",
            "Epoch 276/400\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.1510 - val_loss: 0.3270\n",
            "Epoch 277/400\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.1487 - val_loss: 0.3557\n",
            "Epoch 278/400\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.1481 - val_loss: 0.3970\n",
            "Epoch 279/400\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.1467 - val_loss: 0.4276\n",
            "Epoch 280/400\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.1480 - val_loss: 0.4560\n",
            "Epoch 281/400\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.1486 - val_loss: 0.4618\n",
            "Epoch 282/400\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.1480 - val_loss: 0.4481\n",
            "Epoch 283/400\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.1458 - val_loss: 0.4217\n",
            "Epoch 284/400\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.1454 - val_loss: 0.3877\n",
            "Epoch 285/400\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.1418 - val_loss: 0.3677\n",
            "Epoch 286/400\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.1417 - val_loss: 0.3516\n",
            "Epoch 287/400\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.1401 - val_loss: 0.3498\n",
            "Epoch 288/400\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.1388 - val_loss: 0.3374\n",
            "Epoch 289/400\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.1384 - val_loss: 0.3212\n",
            "Epoch 290/400\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.1377 - val_loss: 0.3173\n",
            "Epoch 291/400\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.1368 - val_loss: 0.3186\n",
            "Epoch 292/400\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.1361 - val_loss: 0.3289\n",
            "Epoch 293/400\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.1350 - val_loss: 0.3409\n",
            "Epoch 294/400\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.1333 - val_loss: 0.3669\n",
            "Epoch 295/400\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.1326 - val_loss: 0.3976\n",
            "Epoch 296/400\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.1335 - val_loss: 0.4253\n",
            "Epoch 297/400\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.1342 - val_loss: 0.4352\n",
            "Epoch 298/400\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.1342 - val_loss: 0.4274\n",
            "Epoch 299/400\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.1330 - val_loss: 0.3968\n",
            "Epoch 300/400\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.1306 - val_loss: 0.3648\n",
            "Epoch 301/400\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.1290 - val_loss: 0.3371\n",
            "Epoch 302/400\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.1283 - val_loss: 0.3166\n",
            "Epoch 303/400\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.1291 - val_loss: 0.3058\n",
            "Epoch 304/400\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.1276 - val_loss: 0.3152\n",
            "Epoch 305/400\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.1267 - val_loss: 0.3249\n",
            "Epoch 306/400\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.1260 - val_loss: 0.3340\n",
            "Epoch 307/400\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.1263 - val_loss: 0.3542\n",
            "Epoch 308/400\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.1247 - val_loss: 0.3566\n",
            "Epoch 309/400\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.1242 - val_loss: 0.3534\n",
            "Epoch 310/400\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.1235 - val_loss: 0.3473\n",
            "Epoch 311/400\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.1229 - val_loss: 0.3385\n",
            "Epoch 312/400\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.1223 - val_loss: 0.3300\n",
            "Epoch 313/400\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.1217 - val_loss: 0.3229\n",
            "Epoch 314/400\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.1213 - val_loss: 0.3202\n",
            "Epoch 315/400\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.1208 - val_loss: 0.3192\n",
            "Epoch 316/400\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.1202 - val_loss: 0.3199\n",
            "Epoch 317/400\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.1198 - val_loss: 0.3244\n",
            "Epoch 318/400\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.1194 - val_loss: 0.3279\n",
            "Epoch 319/400\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.1186 - val_loss: 0.3398\n",
            "Epoch 320/400\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.1189 - val_loss: 0.3464\n",
            "Epoch 321/400\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.1184 - val_loss: 0.3385\n",
            "Epoch 322/400\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.1173 - val_loss: 0.3386\n",
            "Epoch 323/400\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.1168 - val_loss: 0.3353\n",
            "Epoch 324/400\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.1163 - val_loss: 0.3286\n",
            "Epoch 325/400\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.1158 - val_loss: 0.3214\n",
            "Epoch 326/400\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.1154 - val_loss: 0.3143\n",
            "Epoch 327/400\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.1157 - val_loss: 0.3024\n",
            "Epoch 328/400\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.1146 - val_loss: 0.3057\n",
            "Epoch 329/400\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.1144 - val_loss: 0.3099\n",
            "Epoch 330/400\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.1137 - val_loss: 0.3257\n",
            "Epoch 331/400\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.1133 - val_loss: 0.3368\n",
            "Epoch 332/400\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.1131 - val_loss: 0.3415\n",
            "Epoch 333/400\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.1130 - val_loss: 0.3407\n",
            "Epoch 334/400\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.1125 - val_loss: 0.3410\n",
            "Epoch 335/400\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.1122 - val_loss: 0.3317\n",
            "Epoch 336/400\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 0.1115 - val_loss: 0.3199\n",
            "Epoch 337/400\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.1118 - val_loss: 0.3021\n",
            "Epoch 338/400\n",
            "2/2 [==============================] - 0s 77ms/step - loss: 0.1111 - val_loss: 0.2998\n",
            "Epoch 339/400\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 0.1104 - val_loss: 0.3093\n",
            "Epoch 340/400\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 0.1100 - val_loss: 0.3156\n",
            "Epoch 341/400\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.1096 - val_loss: 0.3186\n",
            "Epoch 342/400\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.1094 - val_loss: 0.3183\n",
            "Epoch 343/400\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.1090 - val_loss: 0.3152\n",
            "Epoch 344/400\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.1087 - val_loss: 0.3100\n",
            "Epoch 345/400\n",
            "2/2 [==============================] - 0s 76ms/step - loss: 0.1084 - val_loss: 0.3036\n",
            "Epoch 346/400\n",
            "2/2 [==============================] - 0s 81ms/step - loss: 0.1079 - val_loss: 0.2899\n",
            "Epoch 347/400\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.1075 - val_loss: 0.2734\n",
            "Epoch 348/400\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.1078 - val_loss: 0.2585\n",
            "Epoch 349/400\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.1080 - val_loss: 0.2529\n",
            "Epoch 350/400\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.1080 - val_loss: 0.2501\n",
            "Epoch 351/400\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 0.1078 - val_loss: 0.2560\n",
            "Epoch 352/400\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.1067 - val_loss: 0.2770\n",
            "Epoch 353/400\n",
            "2/2 [==============================] - 0s 76ms/step - loss: 0.1070 - val_loss: 0.3110\n",
            "Epoch 354/400\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 0.1057 - val_loss: 0.3294\n",
            "Epoch 355/400\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.1063 - val_loss: 0.3361\n",
            "Epoch 356/400\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.1057 - val_loss: 0.3232\n",
            "Epoch 357/400\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.1049 - val_loss: 0.3022\n",
            "Epoch 358/400\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.1044 - val_loss: 0.2807\n",
            "Epoch 359/400\n",
            "2/2 [==============================] - 0s 81ms/step - loss: 0.1049 - val_loss: 0.2676\n",
            "Epoch 360/400\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.1041 - val_loss: 0.2708\n",
            "Epoch 361/400\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.1039 - val_loss: 0.2773\n",
            "Epoch 362/400\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.1039 - val_loss: 0.2941\n",
            "Epoch 363/400\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 0.1034 - val_loss: 0.2991\n",
            "Epoch 364/400\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.1029 - val_loss: 0.2931\n",
            "Epoch 365/400\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 0.1028 - val_loss: 0.2874\n",
            "Epoch 366/400\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 0.1023 - val_loss: 0.2890\n",
            "Epoch 367/400\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.1022 - val_loss: 0.2896\n",
            "Epoch 368/400\n",
            "2/2 [==============================] - 0s 76ms/step - loss: 0.1019 - val_loss: 0.2950\n",
            "Epoch 369/400\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.1017 - val_loss: 0.2967\n",
            "Epoch 370/400\n",
            "2/2 [==============================] - 0s 78ms/step - loss: 0.1016 - val_loss: 0.2947\n",
            "Epoch 371/400\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.1015 - val_loss: 0.2909\n",
            "Epoch 372/400\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.1012 - val_loss: 0.2904\n",
            "Epoch 373/400\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.1011 - val_loss: 0.2823\n",
            "Epoch 374/400\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 0.1006 - val_loss: 0.2805\n",
            "Epoch 375/400\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.1004 - val_loss: 0.2782\n",
            "Epoch 376/400\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.1004 - val_loss: 0.2766\n",
            "Epoch 377/400\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.1001 - val_loss: 0.2822\n",
            "Epoch 378/400\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.0998 - val_loss: 0.2917\n",
            "Epoch 379/400\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.1001 - val_loss: 0.3003\n",
            "Epoch 380/400\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.0998 - val_loss: 0.2943\n",
            "Epoch 381/400\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.0995 - val_loss: 0.2842\n",
            "Epoch 382/400\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.0990 - val_loss: 0.2671\n",
            "Epoch 383/400\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.0995 - val_loss: 0.2517\n",
            "Epoch 384/400\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.0991 - val_loss: 0.2510\n",
            "Epoch 385/400\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.0989 - val_loss: 0.2493\n",
            "Epoch 386/400\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.0987 - val_loss: 0.2482\n",
            "Epoch 387/400\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.0985 - val_loss: 0.2562\n",
            "Epoch 388/400\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.0981 - val_loss: 0.2654\n",
            "Epoch 389/400\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.0977 - val_loss: 0.2803\n",
            "Epoch 390/400\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.0979 - val_loss: 0.2930\n",
            "Epoch 391/400\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.0981 - val_loss: 0.2926\n",
            "Epoch 392/400\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.0977 - val_loss: 0.2802\n",
            "Epoch 393/400\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.0976 - val_loss: 0.2648\n",
            "Epoch 394/400\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.0971 - val_loss: 0.2567\n",
            "Epoch 395/400\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.0969 - val_loss: 0.2510\n",
            "Epoch 396/400\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.0968 - val_loss: 0.2442\n",
            "Epoch 397/400\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.0971 - val_loss: 0.2435\n",
            "Epoch 398/400\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.0969 - val_loss: 0.2546\n",
            "Epoch 399/400\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.0965 - val_loss: 0.2602\n",
            "Epoch 400/400\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.0962 - val_loss: 0.2605\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1/400\n",
            "2/2 [==============================] - 1s 193ms/step - loss: 1.1329 - val_loss: 3.5214\n",
            "Epoch 2/400\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1.1253 - val_loss: 3.5177\n",
            "Epoch 3/400\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 1.1192 - val_loss: 3.5140\n",
            "Epoch 4/400\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 1.1138 - val_loss: 3.5103\n",
            "Epoch 5/400\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1.1067 - val_loss: 3.5065\n",
            "Epoch 6/400\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 1.1009 - val_loss: 3.5028\n",
            "Epoch 7/400\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 1.0945 - val_loss: 3.4993\n",
            "Epoch 8/400\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 1.0884 - val_loss: 3.4958\n",
            "Epoch 9/400\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1.0822 - val_loss: 3.4924\n",
            "Epoch 10/400\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 1.0759 - val_loss: 3.4890\n",
            "Epoch 11/400\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 1.0690 - val_loss: 3.4852\n",
            "Epoch 12/400\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 1.0628 - val_loss: 3.4813\n",
            "Epoch 13/400\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 1.0566 - val_loss: 3.4773\n",
            "Epoch 14/400\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 1.0502 - val_loss: 3.4731\n",
            "Epoch 15/400\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 1.0428 - val_loss: 3.4688\n",
            "Epoch 16/400\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 1.0369 - val_loss: 3.4644\n",
            "Epoch 17/400\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1.0306 - val_loss: 3.4600\n",
            "Epoch 18/400\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 1.0237 - val_loss: 3.4555\n",
            "Epoch 19/400\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 1.0166 - val_loss: 3.4510\n",
            "Epoch 20/400\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 1.0105 - val_loss: 3.4464\n",
            "Epoch 21/400\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 1.0035 - val_loss: 3.4418\n",
            "Epoch 22/400\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.9964 - val_loss: 3.4371\n",
            "Epoch 23/400\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.9890 - val_loss: 3.4324\n",
            "Epoch 24/400\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.9820 - val_loss: 3.4276\n",
            "Epoch 25/400\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.9740 - val_loss: 3.4229\n",
            "Epoch 26/400\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.9668 - val_loss: 3.4181\n",
            "Epoch 27/400\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.9585 - val_loss: 3.4135\n",
            "Epoch 28/400\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.9515 - val_loss: 3.4087\n",
            "Epoch 29/400\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.9422 - val_loss: 3.4038\n",
            "Epoch 30/400\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.9351 - val_loss: 3.3985\n",
            "Epoch 31/400\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.9262 - val_loss: 3.3929\n",
            "Epoch 32/400\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.9187 - val_loss: 3.3871\n",
            "Epoch 33/400\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.9098 - val_loss: 3.3811\n",
            "Epoch 34/400\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.9016 - val_loss: 3.3752\n",
            "Epoch 35/400\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.8929 - val_loss: 3.3695\n",
            "Epoch 36/400\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.8846 - val_loss: 3.3638\n",
            "Epoch 37/400\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.8757 - val_loss: 3.3579\n",
            "Epoch 38/400\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.8673 - val_loss: 3.3522\n",
            "Epoch 39/400\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.8581 - val_loss: 3.3466\n",
            "Epoch 40/400\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.8506 - val_loss: 3.3410\n",
            "Epoch 41/400\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.8410 - val_loss: 3.3355\n",
            "Epoch 42/400\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.8324 - val_loss: 3.3298\n",
            "Epoch 43/400\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.8239 - val_loss: 3.3238\n",
            "Epoch 44/400\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.8163 - val_loss: 3.3177\n",
            "Epoch 45/400\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.8064 - val_loss: 3.3117\n",
            "Epoch 46/400\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.7975 - val_loss: 3.3058\n",
            "Epoch 47/400\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.7899 - val_loss: 3.3000\n",
            "Epoch 48/400\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.7804 - val_loss: 3.2946\n",
            "Epoch 49/400\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.7718 - val_loss: 3.2892\n",
            "Epoch 50/400\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.7642 - val_loss: 3.2839\n",
            "Epoch 51/400\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.7542 - val_loss: 3.2788\n",
            "Epoch 52/400\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.7458 - val_loss: 3.2736\n",
            "Epoch 53/400\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.7376 - val_loss: 3.2684\n",
            "Epoch 54/400\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.7291 - val_loss: 3.2633\n",
            "Epoch 55/400\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.7204 - val_loss: 3.2581\n",
            "Epoch 56/400\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.7121 - val_loss: 3.2531\n",
            "Epoch 57/400\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.7039 - val_loss: 3.2482\n",
            "Epoch 58/400\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.6955 - val_loss: 3.2437\n",
            "Epoch 59/400\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.6878 - val_loss: 3.2392\n",
            "Epoch 60/400\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.6797 - val_loss: 3.2345\n",
            "Epoch 61/400\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.6724 - val_loss: 3.2302\n",
            "Epoch 62/400\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.6649 - val_loss: 3.2264\n",
            "Epoch 63/400\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.6574 - val_loss: 3.2231\n",
            "Epoch 64/400\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.6501 - val_loss: 3.2199\n",
            "Epoch 65/400\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.6439 - val_loss: 3.2167\n",
            "Epoch 66/400\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.6369 - val_loss: 3.2134\n",
            "Epoch 67/400\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.6306 - val_loss: 3.2105\n",
            "Epoch 68/400\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.6242 - val_loss: 3.2073\n",
            "Epoch 69/400\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.6179 - val_loss: 3.2040\n",
            "Epoch 70/400\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.6125 - val_loss: 3.2009\n",
            "Epoch 71/400\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.6063 - val_loss: 3.1977\n",
            "Epoch 72/400\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.6010 - val_loss: 3.1949\n",
            "Epoch 73/400\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.5953 - val_loss: 3.1926\n",
            "Epoch 74/400\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.5898 - val_loss: 3.1905\n",
            "Epoch 75/400\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.5844 - val_loss: 3.1885\n",
            "Epoch 76/400\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.5790 - val_loss: 3.1867\n",
            "Epoch 77/400\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.5736 - val_loss: 3.1850\n",
            "Epoch 78/400\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.5684 - val_loss: 3.1836\n",
            "Epoch 79/400\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.5632 - val_loss: 3.1824\n",
            "Epoch 80/400\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.5581 - val_loss: 3.1815\n",
            "Epoch 81/400\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.5531 - val_loss: 3.1808\n",
            "Epoch 82/400\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.5482 - val_loss: 3.1802\n",
            "Epoch 83/400\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.5429 - val_loss: 3.1798\n",
            "Epoch 84/400\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.5382 - val_loss: 3.1795\n",
            "Epoch 85/400\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.5337 - val_loss: 3.1792\n",
            "Epoch 86/400\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.5287 - val_loss: 3.1789\n",
            "Epoch 87/400\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.5241 - val_loss: 3.1787\n",
            "Epoch 88/400\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.5193 - val_loss: 3.1786\n",
            "Epoch 89/400\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.5151 - val_loss: 3.1785\n",
            "Epoch 90/400\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.5109 - val_loss: 3.1783\n",
            "Epoch 91/400\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.5064 - val_loss: 3.1773\n",
            "Epoch 92/400\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.5019 - val_loss: 3.1760\n",
            "Epoch 93/400\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.4980 - val_loss: 3.1748\n",
            "Epoch 94/400\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.4940 - val_loss: 3.1738\n",
            "Epoch 95/400\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.4903 - val_loss: 3.1732\n",
            "Epoch 96/400\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.4864 - val_loss: 3.1726\n",
            "Epoch 97/400\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.4828 - val_loss: 3.1715\n",
            "Epoch 98/400\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.4790 - val_loss: 3.1700\n",
            "Epoch 99/400\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.4755 - val_loss: 3.1687\n",
            "Epoch 100/400\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.4722 - val_loss: 3.1674\n",
            "Epoch 101/400\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.4685 - val_loss: 3.1666\n",
            "Epoch 102/400\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.4652 - val_loss: 3.1662\n",
            "Epoch 103/400\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.4617 - val_loss: 3.1663\n",
            "Epoch 104/400\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.4588 - val_loss: 3.1667\n",
            "Epoch 105/400\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.4552 - val_loss: 3.1670\n",
            "Epoch 106/400\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.4521 - val_loss: 3.1671\n",
            "Epoch 107/400\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.4489 - val_loss: 3.1676\n",
            "Epoch 108/400\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.4459 - val_loss: 3.1685\n",
            "Epoch 109/400\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.4431 - val_loss: 3.1697\n",
            "Epoch 110/400\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.4401 - val_loss: 3.1711\n",
            "Epoch 111/400\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.4376 - val_loss: 3.1726\n",
            "Epoch 112/400\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.4348 - val_loss: 3.1742\n",
            "Epoch 113/400\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.4322 - val_loss: 3.1760\n",
            "Epoch 114/400\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.4298 - val_loss: 3.1778\n",
            "Epoch 115/400\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.4274 - val_loss: 3.1795\n",
            "Epoch 116/400\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.4252 - val_loss: 3.1809\n",
            "Epoch 117/400\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.4227 - val_loss: 3.1823\n",
            "Epoch 118/400\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.4206 - val_loss: 3.1840\n",
            "Epoch 119/400\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.4185 - val_loss: 3.1859\n",
            "Epoch 120/400\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.4163 - val_loss: 3.1877\n",
            "Epoch 121/400\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.4145 - val_loss: 3.1895\n",
            "Epoch 122/400\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.4125 - val_loss: 3.1910\n",
            "Epoch 123/400\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.4107 - val_loss: 3.1923\n",
            "Epoch 124/400\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.4088 - val_loss: 3.1935\n",
            "Epoch 125/400\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.4075 - val_loss: 3.1942\n",
            "Epoch 126/400\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.4056 - val_loss: 3.1933\n",
            "Epoch 127/400\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.4038 - val_loss: 3.1927\n",
            "Epoch 128/400\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.4026 - val_loss: 3.1919\n",
            "Epoch 129/400\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.4010 - val_loss: 3.1898\n",
            "Epoch 130/400\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.3994 - val_loss: 3.1874\n",
            "Epoch 131/400\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.3981 - val_loss: 3.1840\n",
            "Epoch 132/400\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.3966 - val_loss: 3.1801\n",
            "Epoch 133/400\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.3954 - val_loss: 3.1771\n",
            "Epoch 134/400\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.3939 - val_loss: 3.1747\n",
            "Epoch 135/400\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.3927 - val_loss: 3.1728\n",
            "Epoch 136/400\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.3914 - val_loss: 3.1707\n",
            "Epoch 137/400\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.3900 - val_loss: 3.1679\n",
            "Epoch 138/400\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.3887 - val_loss: 3.1661\n",
            "Epoch 139/400\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.3874 - val_loss: 3.1651\n",
            "Epoch 140/400\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.3863 - val_loss: 3.1645\n",
            "Epoch 141/400\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.3851 - val_loss: 3.1638\n",
            "Epoch 142/400\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.3840 - val_loss: 3.1631\n",
            "Epoch 143/400\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.3829 - val_loss: 3.1626\n",
            "Epoch 144/400\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.3818 - val_loss: 3.1624\n",
            "Epoch 145/400\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.3807 - val_loss: 3.1620\n",
            "Epoch 146/400\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.3797 - val_loss: 3.1614\n",
            "Epoch 147/400\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.3789 - val_loss: 3.1602\n",
            "Epoch 148/400\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.3778 - val_loss: 3.1575\n",
            "Epoch 149/400\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.3769 - val_loss: 3.1550\n",
            "Epoch 150/400\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.3758 - val_loss: 3.1528\n",
            "Epoch 151/400\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.3749 - val_loss: 3.1510\n",
            "Epoch 152/400\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.3740 - val_loss: 3.1487\n",
            "Epoch 153/400\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.3730 - val_loss: 3.1454\n",
            "Epoch 154/400\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.3721 - val_loss: 3.1429\n",
            "Epoch 155/400\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.3711 - val_loss: 3.1405\n",
            "Epoch 156/400\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.3703 - val_loss: 3.1380\n",
            "Epoch 157/400\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.3691 - val_loss: 3.1338\n",
            "Epoch 158/400\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.3684 - val_loss: 3.1289\n",
            "Epoch 159/400\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.3673 - val_loss: 3.1245\n",
            "Epoch 160/400\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.3665 - val_loss: 3.1195\n",
            "Epoch 161/400\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 0.3654 - val_loss: 3.1147\n",
            "Epoch 162/400\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.3647 - val_loss: 3.1095\n",
            "Epoch 163/400\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 0.3638 - val_loss: 3.1051\n",
            "Epoch 164/400\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.3629 - val_loss: 3.1015\n",
            "Epoch 165/400\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.3620 - val_loss: 3.0984\n",
            "Epoch 166/400\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 0.3611 - val_loss: 3.0956\n",
            "Epoch 167/400\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 0.3604 - val_loss: 3.0929\n",
            "Epoch 168/400\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 0.3594 - val_loss: 3.0900\n",
            "Epoch 169/400\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.3586 - val_loss: 3.0858\n",
            "Epoch 170/400\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.3579 - val_loss: 3.0811\n",
            "Epoch 171/400\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.3570 - val_loss: 3.0773\n",
            "Epoch 172/400\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.3562 - val_loss: 3.0739\n",
            "Epoch 173/400\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.3552 - val_loss: 3.0706\n",
            "Epoch 174/400\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.3545 - val_loss: 3.0666\n",
            "Epoch 175/400\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.3537 - val_loss: 3.0628\n",
            "Epoch 176/400\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.3529 - val_loss: 3.0591\n",
            "Epoch 177/400\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.3521 - val_loss: 3.0559\n",
            "Epoch 178/400\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 0.3513 - val_loss: 3.0527\n",
            "Epoch 179/400\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.3506 - val_loss: 3.0487\n",
            "Epoch 180/400\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.3496 - val_loss: 3.0446\n",
            "Epoch 181/400\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 0.3488 - val_loss: 3.0391\n",
            "Epoch 182/400\n",
            "2/2 [==============================] - 0s 92ms/step - loss: 0.3482 - val_loss: 3.0331\n",
            "Epoch 183/400\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.3472 - val_loss: 3.0282\n",
            "Epoch 184/400\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.3462 - val_loss: 3.0234\n",
            "Epoch 185/400\n",
            "2/2 [==============================] - 0s 77ms/step - loss: 0.3456 - val_loss: 3.0178\n",
            "Epoch 186/400\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.3447 - val_loss: 3.0128\n",
            "Epoch 187/400\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.3437 - val_loss: 3.0079\n",
            "Epoch 188/400\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.3432 - val_loss: 3.0025\n",
            "Epoch 189/400\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.3423 - val_loss: 2.9981\n",
            "Epoch 190/400\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.3415 - val_loss: 2.9944\n",
            "Epoch 191/400\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.3407 - val_loss: 2.9910\n",
            "Epoch 192/400\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.3399 - val_loss: 2.9882\n",
            "Epoch 193/400\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.3392 - val_loss: 2.9856\n",
            "Epoch 194/400\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.3385 - val_loss: 2.9824\n",
            "Epoch 195/400\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 0.3376 - val_loss: 2.9774\n",
            "Epoch 196/400\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.3367 - val_loss: 2.9713\n",
            "Epoch 197/400\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.3362 - val_loss: 2.9648\n",
            "Epoch 198/400\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 0.3353 - val_loss: 2.9594\n",
            "Epoch 199/400\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 0.3344 - val_loss: 2.9549\n",
            "Epoch 200/400\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.3335 - val_loss: 2.9506\n",
            "Epoch 201/400\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.3328 - val_loss: 2.9454\n",
            "Epoch 202/400\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 0.3318 - val_loss: 2.9402\n",
            "Epoch 203/400\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 0.3311 - val_loss: 2.9342\n",
            "Epoch 204/400\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.3302 - val_loss: 2.9289\n",
            "Epoch 205/400\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 0.3293 - val_loss: 2.9242\n",
            "Epoch 206/400\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.3285 - val_loss: 2.9200\n",
            "Epoch 207/400\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.3277 - val_loss: 2.9156\n",
            "Epoch 208/400\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.3269 - val_loss: 2.9100\n",
            "Epoch 209/400\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.3259 - val_loss: 2.9042\n",
            "Epoch 210/400\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.3253 - val_loss: 2.8977\n",
            "Epoch 211/400\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.3244 - val_loss: 2.8917\n",
            "Epoch 212/400\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.3237 - val_loss: 2.8862\n",
            "Epoch 213/400\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.3229 - val_loss: 2.8814\n",
            "Epoch 214/400\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.3221 - val_loss: 2.8773\n",
            "Epoch 215/400\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.3214 - val_loss: 2.8737\n",
            "Epoch 216/400\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.3207 - val_loss: 2.8701\n",
            "Epoch 217/400\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.3199 - val_loss: 2.8659\n",
            "Epoch 218/400\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.3192 - val_loss: 2.8605\n",
            "Epoch 219/400\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.3183 - val_loss: 2.8549\n",
            "Epoch 220/400\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.3177 - val_loss: 2.8483\n",
            "Epoch 221/400\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.3168 - val_loss: 2.8427\n",
            "Epoch 222/400\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.3160 - val_loss: 2.8379\n",
            "Epoch 223/400\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.3150 - val_loss: 2.8328\n",
            "Epoch 224/400\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.3144 - val_loss: 2.8266\n",
            "Epoch 225/400\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.3133 - val_loss: 2.8203\n",
            "Epoch 226/400\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.3123 - val_loss: 2.8126\n",
            "Epoch 227/400\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.3113 - val_loss: 2.8038\n",
            "Epoch 228/400\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.3102 - val_loss: 2.7940\n",
            "Epoch 229/400\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.3097 - val_loss: 2.7840\n",
            "Epoch 230/400\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.3086 - val_loss: 2.7755\n",
            "Epoch 231/400\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.3076 - val_loss: 2.7679\n",
            "Epoch 232/400\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.3066 - val_loss: 2.7612\n",
            "Epoch 233/400\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.3057 - val_loss: 2.7550\n",
            "Epoch 234/400\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.3048 - val_loss: 2.7493\n",
            "Epoch 235/400\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.3039 - val_loss: 2.7443\n",
            "Epoch 236/400\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.3029 - val_loss: 2.7393\n",
            "Epoch 237/400\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.3022 - val_loss: 2.7331\n",
            "Epoch 238/400\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.3012 - val_loss: 2.7275\n",
            "Epoch 239/400\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.3003 - val_loss: 2.7222\n",
            "Epoch 240/400\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.2995 - val_loss: 2.7171\n",
            "Epoch 241/400\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.2987 - val_loss: 2.7121\n",
            "Epoch 242/400\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.2979 - val_loss: 2.7072\n",
            "Epoch 243/400\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.2971 - val_loss: 2.7024\n",
            "Epoch 244/400\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.2963 - val_loss: 2.6976\n",
            "Epoch 245/400\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.2955 - val_loss: 2.6929\n",
            "Epoch 246/400\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.2948 - val_loss: 2.6885\n",
            "Epoch 247/400\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.2941 - val_loss: 2.6841\n",
            "Epoch 248/400\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.2934 - val_loss: 2.6796\n",
            "Epoch 249/400\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.2927 - val_loss: 2.6749\n",
            "Epoch 250/400\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.2920 - val_loss: 2.6698\n",
            "Epoch 251/400\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.2913 - val_loss: 2.6647\n",
            "Epoch 252/400\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.2905 - val_loss: 2.6587\n",
            "Epoch 253/400\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.2894 - val_loss: 2.6494\n",
            "Epoch 254/400\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.2889 - val_loss: 2.6386\n",
            "Epoch 255/400\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.2873 - val_loss: 2.6284\n",
            "Epoch 256/400\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.2867 - val_loss: 2.6169\n",
            "Epoch 257/400\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.2855 - val_loss: 2.6067\n",
            "Epoch 258/400\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.2843 - val_loss: 2.5976\n",
            "Epoch 259/400\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.2830 - val_loss: 2.5881\n",
            "Epoch 260/400\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.2823 - val_loss: 2.5770\n",
            "Epoch 261/400\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.2812 - val_loss: 2.5667\n",
            "Epoch 262/400\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.2797 - val_loss: 2.5564\n",
            "Epoch 263/400\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.2786 - val_loss: 2.5440\n",
            "Epoch 264/400\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.2773 - val_loss: 2.5301\n",
            "Epoch 265/400\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.2767 - val_loss: 2.5157\n",
            "Epoch 266/400\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.2747 - val_loss: 2.5021\n",
            "Epoch 267/400\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.2740 - val_loss: 2.4878\n",
            "Epoch 268/400\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.2727 - val_loss: 2.4749\n",
            "Epoch 269/400\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.2714 - val_loss: 2.4632\n",
            "Epoch 270/400\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.2702 - val_loss: 2.4525\n",
            "Epoch 271/400\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.2691 - val_loss: 2.4428\n",
            "Epoch 272/400\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.2676 - val_loss: 2.4330\n",
            "Epoch 273/400\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.2664 - val_loss: 2.4204\n",
            "Epoch 274/400\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.2656 - val_loss: 2.4063\n",
            "Epoch 275/400\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.2642 - val_loss: 2.3939\n",
            "Epoch 276/400\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.2630 - val_loss: 2.3826\n",
            "Epoch 277/400\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.2613 - val_loss: 2.3713\n",
            "Epoch 278/400\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.2600 - val_loss: 2.3575\n",
            "Epoch 279/400\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.2592 - val_loss: 2.3430\n",
            "Epoch 280/400\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.2572 - val_loss: 2.3294\n",
            "Epoch 281/400\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.2557 - val_loss: 2.3130\n",
            "Epoch 282/400\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.2548 - val_loss: 2.2952\n",
            "Epoch 283/400\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.2531 - val_loss: 2.2799\n",
            "Epoch 284/400\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.2512 - val_loss: 2.2651\n",
            "Epoch 285/400\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.2503 - val_loss: 2.2487\n",
            "Epoch 286/400\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.2488 - val_loss: 2.2347\n",
            "Epoch 287/400\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.2473 - val_loss: 2.2226\n",
            "Epoch 288/400\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.2460 - val_loss: 2.2127\n",
            "Epoch 289/400\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.2448 - val_loss: 2.2040\n",
            "Epoch 290/400\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.2436 - val_loss: 2.1957\n",
            "Epoch 291/400\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.2426 - val_loss: 2.1878\n",
            "Epoch 292/400\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.2416 - val_loss: 2.1800\n",
            "Epoch 293/400\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.2407 - val_loss: 2.1705\n",
            "Epoch 294/400\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.2398 - val_loss: 2.1564\n",
            "Epoch 295/400\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.2385 - val_loss: 2.1428\n",
            "Epoch 296/400\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.2373 - val_loss: 2.1298\n",
            "Epoch 297/400\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.2358 - val_loss: 2.1157\n",
            "Epoch 298/400\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.2350 - val_loss: 2.0982\n",
            "Epoch 299/400\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.2336 - val_loss: 2.0820\n",
            "Epoch 300/400\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.2322 - val_loss: 2.0665\n",
            "Epoch 301/400\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.2310 - val_loss: 2.0520\n",
            "Epoch 302/400\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.2299 - val_loss: 2.0386\n",
            "Epoch 303/400\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.2287 - val_loss: 2.0266\n",
            "Epoch 304/400\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.2274 - val_loss: 2.0134\n",
            "Epoch 305/400\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.2260 - val_loss: 1.9940\n",
            "Epoch 306/400\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.2253 - val_loss: 1.9718\n",
            "Epoch 307/400\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.2237 - val_loss: 1.9523\n",
            "Epoch 308/400\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.2224 - val_loss: 1.9346\n",
            "Epoch 309/400\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.2212 - val_loss: 1.9187\n",
            "Epoch 310/400\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.2199 - val_loss: 1.9047\n",
            "Epoch 311/400\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.2186 - val_loss: 1.8895\n",
            "Epoch 312/400\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.2171 - val_loss: 1.8683\n",
            "Epoch 313/400\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.2166 - val_loss: 1.8455\n",
            "Epoch 314/400\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.2150 - val_loss: 1.8270\n",
            "Epoch 315/400\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.2136 - val_loss: 1.8116\n",
            "Epoch 316/400\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.2122 - val_loss: 1.7979\n",
            "Epoch 317/400\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.2109 - val_loss: 1.7838\n",
            "Epoch 318/400\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.2099 - val_loss: 1.7654\n",
            "Epoch 319/400\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.2084 - val_loss: 1.7501\n",
            "Epoch 320/400\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.2072 - val_loss: 1.7365\n",
            "Epoch 321/400\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.2058 - val_loss: 1.7227\n",
            "Epoch 322/400\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.2050 - val_loss: 1.7049\n",
            "Epoch 323/400\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.2036 - val_loss: 1.6899\n",
            "Epoch 324/400\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.2022 - val_loss: 1.6734\n",
            "Epoch 325/400\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.2013 - val_loss: 1.6528\n",
            "Epoch 326/400\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.1996 - val_loss: 1.6314\n",
            "Epoch 327/400\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.1991 - val_loss: 1.6066\n",
            "Epoch 328/400\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.1977 - val_loss: 1.5874\n",
            "Epoch 329/400\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.1964 - val_loss: 1.5728\n",
            "Epoch 330/400\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.1953 - val_loss: 1.5616\n",
            "Epoch 331/400\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.1943 - val_loss: 1.5481\n",
            "Epoch 332/400\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.1933 - val_loss: 1.5290\n",
            "Epoch 333/400\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.1922 - val_loss: 1.5129\n",
            "Epoch 334/400\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.1912 - val_loss: 1.4989\n",
            "Epoch 335/400\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.1902 - val_loss: 1.4878\n",
            "Epoch 336/400\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.1893 - val_loss: 1.4785\n",
            "Epoch 337/400\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.1885 - val_loss: 1.4726\n",
            "Epoch 338/400\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.1878 - val_loss: 1.4656\n",
            "Epoch 339/400\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.1873 - val_loss: 1.4545\n",
            "Epoch 340/400\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.1860 - val_loss: 1.4331\n",
            "Epoch 341/400\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.1855 - val_loss: 1.4084\n",
            "Epoch 342/400\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.1844 - val_loss: 1.3884\n",
            "Epoch 343/400\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.1833 - val_loss: 1.3725\n",
            "Epoch 344/400\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.1825 - val_loss: 1.3586\n",
            "Epoch 345/400\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.1817 - val_loss: 1.3481\n",
            "Epoch 346/400\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.1809 - val_loss: 1.3381\n",
            "Epoch 347/400\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.1803 - val_loss: 1.3294\n",
            "Epoch 348/400\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.1796 - val_loss: 1.3202\n",
            "Epoch 349/400\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.1790 - val_loss: 1.3105\n",
            "Epoch 350/400\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.1785 - val_loss: 1.3016\n",
            "Epoch 351/400\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.1778 - val_loss: 1.2950\n",
            "Epoch 352/400\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.1774 - val_loss: 1.2886\n",
            "Epoch 353/400\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.1769 - val_loss: 1.2816\n",
            "Epoch 354/400\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.1765 - val_loss: 1.2741\n",
            "Epoch 355/400\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.1760 - val_loss: 1.2682\n",
            "Epoch 356/400\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.1756 - val_loss: 1.2626\n",
            "Epoch 357/400\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.1753 - val_loss: 1.2547\n",
            "Epoch 358/400\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.1749 - val_loss: 1.2448\n",
            "Epoch 359/400\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.1744 - val_loss: 1.2340\n",
            "Epoch 360/400\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.1739 - val_loss: 1.2232\n",
            "Epoch 361/400\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.1733 - val_loss: 1.2132\n",
            "Epoch 362/400\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.1729 - val_loss: 1.2027\n",
            "Epoch 363/400\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.1723 - val_loss: 1.1932\n",
            "Epoch 364/400\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.1718 - val_loss: 1.1790\n",
            "Epoch 365/400\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.1713 - val_loss: 1.1574\n",
            "Epoch 366/400\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.1701 - val_loss: 1.1358\n",
            "Epoch 367/400\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.1702 - val_loss: 1.1122\n",
            "Epoch 368/400\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.1691 - val_loss: 1.0958\n",
            "Epoch 369/400\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.1686 - val_loss: 1.0817\n",
            "Epoch 370/400\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.1680 - val_loss: 1.0673\n",
            "Epoch 371/400\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.1678 - val_loss: 1.0499\n",
            "Epoch 372/400\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.1675 - val_loss: 1.0380\n",
            "Epoch 373/400\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.1669 - val_loss: 1.0320\n",
            "Epoch 374/400\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.1663 - val_loss: 1.0283\n",
            "Epoch 375/400\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.1658 - val_loss: 1.0272\n",
            "Epoch 376/400\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.1655 - val_loss: 1.0232\n",
            "Epoch 377/400\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.1651 - val_loss: 1.0188\n",
            "Epoch 378/400\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.1648 - val_loss: 1.0143\n",
            "Epoch 379/400\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.1645 - val_loss: 1.0063\n",
            "Epoch 380/400\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.1643 - val_loss: 0.9933\n",
            "Epoch 381/400\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.1637 - val_loss: 0.9842\n",
            "Epoch 382/400\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.1634 - val_loss: 0.9764\n",
            "Epoch 383/400\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.1631 - val_loss: 0.9711\n",
            "Epoch 384/400\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.1629 - val_loss: 0.9627\n",
            "Epoch 385/400\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.1626 - val_loss: 0.9479\n",
            "Epoch 386/400\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.1622 - val_loss: 0.9345\n",
            "Epoch 387/400\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.1617 - val_loss: 0.9217\n",
            "Epoch 388/400\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.1616 - val_loss: 0.9086\n",
            "Epoch 389/400\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.1612 - val_loss: 0.8960\n",
            "Epoch 390/400\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.1611 - val_loss: 0.8812\n",
            "Epoch 391/400\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.1609 - val_loss: 0.8696\n",
            "Epoch 392/400\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.1607 - val_loss: 0.8597\n",
            "Epoch 393/400\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.1606 - val_loss: 0.8488\n",
            "Epoch 394/400\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.1605 - val_loss: 0.8410\n",
            "Epoch 395/400\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.1603 - val_loss: 0.8348\n",
            "Epoch 396/400\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.1601 - val_loss: 0.8278\n",
            "Epoch 397/400\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.1600 - val_loss: 0.8219\n",
            "Epoch 398/400\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.1598 - val_loss: 0.8153\n",
            "Epoch 399/400\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.1596 - val_loss: 0.8126\n",
            "Epoch 400/400\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.1592 - val_loss: 0.8164\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1/400\n",
            "2/2 [==============================] - 1s 188ms/step - loss: 1.5363 - val_loss: 1.7833\n",
            "Epoch 2/400\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 1.5316 - val_loss: 1.7727\n",
            "Epoch 3/400\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 1.5275 - val_loss: 1.7624\n",
            "Epoch 4/400\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 1.5228 - val_loss: 1.7525\n",
            "Epoch 5/400\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 1.5189 - val_loss: 1.7425\n",
            "Epoch 6/400\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 1.5154 - val_loss: 1.7331\n",
            "Epoch 7/400\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 1.5113 - val_loss: 1.7245\n",
            "Epoch 8/400\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 1.5079 - val_loss: 1.7165\n",
            "Epoch 9/400\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 1.5042 - val_loss: 1.7086\n",
            "Epoch 10/400\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 1.5008 - val_loss: 1.7005\n",
            "Epoch 11/400\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 1.4976 - val_loss: 1.6923\n",
            "Epoch 12/400\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 1.4939 - val_loss: 1.6840\n",
            "Epoch 13/400\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 1.4909 - val_loss: 1.6754\n",
            "Epoch 14/400\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 1.4874 - val_loss: 1.6669\n",
            "Epoch 15/400\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 1.4843 - val_loss: 1.6584\n",
            "Epoch 16/400\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 1.4811 - val_loss: 1.6503\n",
            "Epoch 17/400\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 1.4779 - val_loss: 1.6424\n",
            "Epoch 18/400\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 1.4749 - val_loss: 1.6345\n",
            "Epoch 19/400\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 1.4718 - val_loss: 1.6266\n",
            "Epoch 20/400\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 1.4687 - val_loss: 1.6185\n",
            "Epoch 21/400\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 1.4660 - val_loss: 1.6108\n",
            "Epoch 22/400\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 1.4628 - val_loss: 1.6034\n",
            "Epoch 23/400\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 1.4604 - val_loss: 1.5967\n",
            "Epoch 24/400\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 1.4572 - val_loss: 1.5906\n",
            "Epoch 25/400\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 1.4548 - val_loss: 1.5845\n",
            "Epoch 26/400\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 1.4519 - val_loss: 1.5783\n",
            "Epoch 27/400\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 1.4495 - val_loss: 1.5714\n",
            "Epoch 28/400\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 1.4468 - val_loss: 1.5645\n",
            "Epoch 29/400\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 1.4438 - val_loss: 1.5574\n",
            "Epoch 30/400\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 1.4411 - val_loss: 1.5497\n",
            "Epoch 31/400\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 1.4383 - val_loss: 1.5417\n",
            "Epoch 32/400\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 1.4356 - val_loss: 1.5340\n",
            "Epoch 33/400\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 1.4327 - val_loss: 1.5268\n",
            "Epoch 34/400\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 1.4300 - val_loss: 1.5197\n",
            "Epoch 35/400\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 1.4274 - val_loss: 1.5127\n",
            "Epoch 36/400\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 1.4251 - val_loss: 1.5060\n",
            "Epoch 37/400\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 1.4226 - val_loss: 1.5004\n",
            "Epoch 38/400\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 1.4201 - val_loss: 1.4953\n",
            "Epoch 39/400\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 1.4178 - val_loss: 1.4894\n",
            "Epoch 40/400\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 1.4152 - val_loss: 1.4826\n",
            "Epoch 41/400\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 1.4126 - val_loss: 1.4747\n",
            "Epoch 42/400\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 1.4100 - val_loss: 1.4668\n",
            "Epoch 43/400\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 1.4067 - val_loss: 1.4589\n",
            "Epoch 44/400\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 1.4038 - val_loss: 1.4505\n",
            "Epoch 45/400\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 1.4009 - val_loss: 1.4422\n",
            "Epoch 46/400\n",
            "2/2 [==============================] - 0s 76ms/step - loss: 1.3978 - val_loss: 1.4347\n",
            "Epoch 47/400\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 1.3945 - val_loss: 1.4272\n",
            "Epoch 48/400\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 1.3917 - val_loss: 1.4191\n",
            "Epoch 49/400\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 1.3885 - val_loss: 1.4109\n",
            "Epoch 50/400\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 1.3850 - val_loss: 1.4018\n",
            "Epoch 51/400\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 1.3815 - val_loss: 1.3916\n",
            "Epoch 52/400\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 1.3777 - val_loss: 1.3806\n",
            "Epoch 53/400\n",
            "2/2 [==============================] - 0s 81ms/step - loss: 1.3733 - val_loss: 1.3687\n",
            "Epoch 54/400\n",
            "2/2 [==============================] - 0s 82ms/step - loss: 1.3695 - val_loss: 1.3562\n",
            "Epoch 55/400\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 1.3651 - val_loss: 1.3439\n",
            "Epoch 56/400\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 1.3601 - val_loss: 1.3314\n",
            "Epoch 57/400\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 1.3563 - val_loss: 1.3190\n",
            "Epoch 58/400\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 1.3514 - val_loss: 1.3073\n",
            "Epoch 59/400\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 1.3469 - val_loss: 1.2959\n",
            "Epoch 60/400\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 1.3423 - val_loss: 1.2846\n",
            "Epoch 61/400\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 1.3375 - val_loss: 1.2727\n",
            "Epoch 62/400\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 1.3332 - val_loss: 1.2608\n",
            "Epoch 63/400\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 1.3281 - val_loss: 1.2491\n",
            "Epoch 64/400\n",
            "2/2 [==============================] - 0s 75ms/step - loss: 1.3234 - val_loss: 1.2367\n",
            "Epoch 65/400\n",
            "2/2 [==============================] - 0s 81ms/step - loss: 1.3184 - val_loss: 1.2242\n",
            "Epoch 66/400\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 1.3127 - val_loss: 1.2108\n",
            "Epoch 67/400\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 1.3082 - val_loss: 1.1967\n",
            "Epoch 68/400\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 1.3028 - val_loss: 1.1839\n",
            "Epoch 69/400\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 1.2971 - val_loss: 1.1721\n",
            "Epoch 70/400\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 1.2918 - val_loss: 1.1599\n",
            "Epoch 71/400\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 1.2863 - val_loss: 1.1465\n",
            "Epoch 72/400\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 1.2814 - val_loss: 1.1327\n",
            "Epoch 73/400\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 1.2751 - val_loss: 1.1188\n",
            "Epoch 74/400\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 1.2702 - val_loss: 1.1049\n",
            "Epoch 75/400\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 1.2644 - val_loss: 1.0919\n",
            "Epoch 76/400\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 1.2590 - val_loss: 1.0792\n",
            "Epoch 77/400\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 1.2533 - val_loss: 1.0663\n",
            "Epoch 78/400\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 1.2484 - val_loss: 1.0528\n",
            "Epoch 79/400\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 1.2431 - val_loss: 1.0398\n",
            "Epoch 80/400\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 1.2376 - val_loss: 1.0274\n",
            "Epoch 81/400\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 1.2320 - val_loss: 1.0142\n",
            "Epoch 82/400\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 1.2256 - val_loss: 0.9990\n",
            "Epoch 83/400\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 1.2196 - val_loss: 0.9824\n",
            "Epoch 84/400\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 1.2127 - val_loss: 0.9660\n",
            "Epoch 85/400\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 1.2055 - val_loss: 0.9497\n",
            "Epoch 86/400\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 1.1990 - val_loss: 0.9339\n",
            "Epoch 87/400\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 1.1915 - val_loss: 0.9190\n",
            "Epoch 88/400\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 1.1850 - val_loss: 0.9042\n",
            "Epoch 89/400\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 1.1777 - val_loss: 0.8891\n",
            "Epoch 90/400\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 1.1712 - val_loss: 0.8735\n",
            "Epoch 91/400\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 1.1645 - val_loss: 0.8585\n",
            "Epoch 92/400\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 1.1570 - val_loss: 0.8434\n",
            "Epoch 93/400\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 1.1508 - val_loss: 0.8285\n",
            "Epoch 94/400\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 1.1437 - val_loss: 0.8143\n",
            "Epoch 95/400\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 1.1374 - val_loss: 0.8003\n",
            "Epoch 96/400\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 1.1309 - val_loss: 0.7867\n",
            "Epoch 97/400\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 1.1241 - val_loss: 0.7728\n",
            "Epoch 98/400\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 1.1178 - val_loss: 0.7590\n",
            "Epoch 99/400\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 1.1108 - val_loss: 0.7455\n",
            "Epoch 100/400\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 1.1042 - val_loss: 0.7325\n",
            "Epoch 101/400\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 1.0968 - val_loss: 0.7208\n",
            "Epoch 102/400\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 1.0900 - val_loss: 0.7095\n",
            "Epoch 103/400\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 1.0829 - val_loss: 0.6977\n",
            "Epoch 104/400\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 1.0760 - val_loss: 0.6860\n",
            "Epoch 105/400\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 1.0689 - val_loss: 0.6747\n",
            "Epoch 106/400\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 1.0626 - val_loss: 0.6637\n",
            "Epoch 107/400\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 1.0563 - val_loss: 0.6534\n",
            "Epoch 108/400\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 1.0502 - val_loss: 0.6438\n",
            "Epoch 109/400\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 1.0443 - val_loss: 0.6348\n",
            "Epoch 110/400\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 1.0385 - val_loss: 0.6259\n",
            "Epoch 111/400\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 1.0322 - val_loss: 0.6172\n",
            "Epoch 112/400\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 1.0271 - val_loss: 0.6088\n",
            "Epoch 113/400\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 1.0215 - val_loss: 0.6011\n",
            "Epoch 114/400\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 1.0165 - val_loss: 0.5941\n",
            "Epoch 115/400\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 1.0114 - val_loss: 0.5875\n",
            "Epoch 116/400\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 1.0062 - val_loss: 0.5806\n",
            "Epoch 117/400\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 1.0013 - val_loss: 0.5737\n",
            "Epoch 118/400\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.9961 - val_loss: 0.5673\n",
            "Epoch 119/400\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.9909 - val_loss: 0.5610\n",
            "Epoch 120/400\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.9860 - val_loss: 0.5549\n",
            "Epoch 121/400\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.9806 - val_loss: 0.5493\n",
            "Epoch 122/400\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.9759 - val_loss: 0.5437\n",
            "Epoch 123/400\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.9710 - val_loss: 0.5382\n",
            "Epoch 124/400\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.9667 - val_loss: 0.5329\n",
            "Epoch 125/400\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.9623 - val_loss: 0.5280\n",
            "Epoch 126/400\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.9578 - val_loss: 0.5233\n",
            "Epoch 127/400\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.9539 - val_loss: 0.5188\n",
            "Epoch 128/400\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.9498 - val_loss: 0.5143\n",
            "Epoch 129/400\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.9459 - val_loss: 0.5099\n",
            "Epoch 130/400\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.9416 - val_loss: 0.5057\n",
            "Epoch 131/400\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.9376 - val_loss: 0.5015\n",
            "Epoch 132/400\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.9335 - val_loss: 0.4976\n",
            "Epoch 133/400\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.9297 - val_loss: 0.4940\n",
            "Epoch 134/400\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.9257 - val_loss: 0.4908\n",
            "Epoch 135/400\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.9218 - val_loss: 0.4877\n",
            "Epoch 136/400\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.9178 - val_loss: 0.4847\n",
            "Epoch 137/400\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.9140 - val_loss: 0.4817\n",
            "Epoch 138/400\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.9101 - val_loss: 0.4788\n",
            "Epoch 139/400\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.9057 - val_loss: 0.4762\n",
            "Epoch 140/400\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.9011 - val_loss: 0.4737\n",
            "Epoch 141/400\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.8964 - val_loss: 0.4712\n",
            "Epoch 142/400\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.8903 - val_loss: 0.4690\n",
            "Epoch 143/400\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.8858 - val_loss: 0.4669\n",
            "Epoch 144/400\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.8802 - val_loss: 0.4648\n",
            "Epoch 145/400\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.8746 - val_loss: 0.4627\n",
            "Epoch 146/400\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.8692 - val_loss: 0.4608\n",
            "Epoch 147/400\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.8640 - val_loss: 0.4589\n",
            "Epoch 148/400\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.8589 - val_loss: 0.4570\n",
            "Epoch 149/400\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.8543 - val_loss: 0.4554\n",
            "Epoch 150/400\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.8474 - val_loss: 0.4539\n",
            "Epoch 151/400\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.8409 - val_loss: 0.4525\n",
            "Epoch 152/400\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.8360 - val_loss: 0.4512\n",
            "Epoch 153/400\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.8282 - val_loss: 0.4500\n",
            "Epoch 154/400\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.8214 - val_loss: 0.4489\n",
            "Epoch 155/400\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.8124 - val_loss: 0.4477\n",
            "Epoch 156/400\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.8074 - val_loss: 0.4467\n",
            "Epoch 157/400\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.7998 - val_loss: 0.4456\n",
            "Epoch 158/400\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.7905 - val_loss: 0.4446\n",
            "Epoch 159/400\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.7846 - val_loss: 0.4437\n",
            "Epoch 160/400\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.7762 - val_loss: 0.4427\n",
            "Epoch 161/400\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.7681 - val_loss: 0.4418\n",
            "Epoch 162/400\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.7608 - val_loss: 0.4408\n",
            "Epoch 163/400\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.7532 - val_loss: 0.4398\n",
            "Epoch 164/400\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.7435 - val_loss: 0.4389\n",
            "Epoch 165/400\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.7369 - val_loss: 0.4379\n",
            "Epoch 166/400\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.7274 - val_loss: 0.4370\n",
            "Epoch 167/400\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.7168 - val_loss: 0.4361\n",
            "Epoch 168/400\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.7079 - val_loss: 0.4352\n",
            "Epoch 169/400\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.6986 - val_loss: 0.4344\n",
            "Epoch 170/400\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.6895 - val_loss: 0.4337\n",
            "Epoch 171/400\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.6805 - val_loss: 0.4330\n",
            "Epoch 172/400\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.6710 - val_loss: 0.4322\n",
            "Epoch 173/400\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.6629 - val_loss: 0.4315\n",
            "Epoch 174/400\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.6517 - val_loss: 0.4308\n",
            "Epoch 175/400\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.6417 - val_loss: 0.4301\n",
            "Epoch 176/400\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.6250 - val_loss: 0.4294\n",
            "Epoch 177/400\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.6087 - val_loss: 0.4288\n",
            "Epoch 178/400\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.5994 - val_loss: 0.4282\n",
            "Epoch 179/400\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.5753 - val_loss: 0.4277\n",
            "Epoch 180/400\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.5669 - val_loss: 0.4271\n",
            "Epoch 181/400\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.5511 - val_loss: 0.4265\n",
            "Epoch 182/400\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.5336 - val_loss: 0.4259\n",
            "Epoch 183/400\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.5275 - val_loss: 0.4254\n",
            "Epoch 184/400\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.5180 - val_loss: 0.4249\n",
            "Epoch 185/400\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.5095 - val_loss: 0.4244\n",
            "Epoch 186/400\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.5022 - val_loss: 0.4240\n",
            "Epoch 187/400\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.4962 - val_loss: 0.4236\n",
            "Epoch 188/400\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.4906 - val_loss: 0.4232\n",
            "Epoch 189/400\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.4850 - val_loss: 0.4228\n",
            "Epoch 190/400\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.4790 - val_loss: 0.4223\n",
            "Epoch 191/400\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.4728 - val_loss: 0.4219\n",
            "Epoch 192/400\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.4647 - val_loss: 0.4215\n",
            "Epoch 193/400\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.4583 - val_loss: 0.4211\n",
            "Epoch 194/400\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.4509 - val_loss: 0.4208\n",
            "Epoch 195/400\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.4440 - val_loss: 0.4204\n",
            "Epoch 196/400\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.4374 - val_loss: 0.4201\n",
            "Epoch 197/400\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.4319 - val_loss: 0.4198\n",
            "Epoch 198/400\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.4257 - val_loss: 0.4196\n",
            "Epoch 199/400\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.4221 - val_loss: 0.4194\n",
            "Epoch 200/400\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.4166 - val_loss: 0.4192\n",
            "Epoch 201/400\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.4186 - val_loss: 0.4189\n",
            "Epoch 202/400\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.4146 - val_loss: 0.4187\n",
            "Epoch 203/400\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.4079 - val_loss: 0.4185\n",
            "Epoch 204/400\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.3984 - val_loss: 0.4182\n",
            "Epoch 205/400\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.3883 - val_loss: 0.4179\n",
            "Epoch 206/400\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.3827 - val_loss: 0.4177\n",
            "Epoch 207/400\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.3768 - val_loss: 0.4174\n",
            "Epoch 208/400\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.3734 - val_loss: 0.4172\n",
            "Epoch 209/400\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.3708 - val_loss: 0.4170\n",
            "Epoch 210/400\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.3705 - val_loss: 0.4168\n",
            "Epoch 211/400\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.3701 - val_loss: 0.4167\n",
            "Epoch 212/400\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.3695 - val_loss: 0.4165\n",
            "Epoch 213/400\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.3669 - val_loss: 0.4164\n",
            "Epoch 214/400\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.3640 - val_loss: 0.4163\n",
            "Epoch 215/400\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.3538 - val_loss: 0.4162\n",
            "Epoch 216/400\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.3495 - val_loss: 0.4161\n",
            "Epoch 217/400\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.3399 - val_loss: 0.4160\n",
            "Epoch 218/400\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.3322 - val_loss: 0.4159\n",
            "Epoch 219/400\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.3291 - val_loss: 0.4159\n",
            "Epoch 220/400\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.3323 - val_loss: 0.4158\n",
            "Epoch 221/400\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.3473 - val_loss: 0.4157\n",
            "Epoch 222/400\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.3529 - val_loss: 0.4156\n",
            "Epoch 223/400\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.3547 - val_loss: 0.4155\n",
            "Epoch 224/400\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.3544 - val_loss: 0.4154\n",
            "Epoch 225/400\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.3589 - val_loss: 0.4153\n",
            "Epoch 226/400\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.3522 - val_loss: 0.4151\n",
            "Epoch 227/400\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.3370 - val_loss: 0.4150\n",
            "Epoch 228/400\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.3246 - val_loss: 0.4149\n",
            "Epoch 229/400\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.3122 - val_loss: 0.4147\n",
            "Epoch 230/400\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.3006 - val_loss: 0.4146\n",
            "Epoch 231/400\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.2938 - val_loss: 0.4145\n",
            "Epoch 232/400\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.2875 - val_loss: 0.4144\n",
            "Epoch 233/400\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.2824 - val_loss: 0.4143\n",
            "Epoch 234/400\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.2810 - val_loss: 0.4142\n",
            "Epoch 235/400\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.2769 - val_loss: 0.4141\n",
            "Epoch 236/400\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.2742 - val_loss: 0.4141\n",
            "Epoch 237/400\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.2714 - val_loss: 0.4140\n",
            "Epoch 238/400\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.2696 - val_loss: 0.4139\n",
            "Epoch 239/400\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.2676 - val_loss: 0.4139\n",
            "Epoch 240/400\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.2661 - val_loss: 0.4138\n",
            "Epoch 241/400\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.2646 - val_loss: 0.4137\n",
            "Epoch 242/400\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.2636 - val_loss: 0.4137\n",
            "Epoch 243/400\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.2624 - val_loss: 0.4136\n",
            "Epoch 244/400\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.2615 - val_loss: 0.4136\n",
            "Epoch 245/400\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.2606 - val_loss: 0.4136\n",
            "Epoch 246/400\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.2595 - val_loss: 0.4135\n",
            "Epoch 247/400\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.2586 - val_loss: 0.4135\n",
            "Epoch 248/400\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.2575 - val_loss: 0.4134\n",
            "Epoch 249/400\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.2561 - val_loss: 0.4134\n",
            "Epoch 250/400\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.2548 - val_loss: 0.4134\n",
            "Epoch 251/400\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.2532 - val_loss: 0.4134\n",
            "Epoch 252/400\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.2518 - val_loss: 0.4133\n",
            "Epoch 253/400\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.2502 - val_loss: 0.4133\n",
            "Epoch 254/400\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.2486 - val_loss: 0.4133\n",
            "Epoch 255/400\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.2469 - val_loss: 0.4132\n",
            "Epoch 256/400\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.2455 - val_loss: 0.4132\n",
            "Epoch 257/400\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.2443 - val_loss: 0.4132\n",
            "Epoch 258/400\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.2431 - val_loss: 0.4132\n",
            "Epoch 259/400\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.2414 - val_loss: 0.4131\n",
            "Epoch 260/400\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.2390 - val_loss: 0.4131\n",
            "Epoch 261/400\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.2362 - val_loss: 0.4131\n",
            "Epoch 262/400\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.2349 - val_loss: 0.4131\n",
            "Epoch 263/400\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.2345 - val_loss: 0.4131\n",
            "Epoch 264/400\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.2342 - val_loss: 0.4131\n",
            "Epoch 265/400\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.2338 - val_loss: 0.4130\n",
            "Epoch 266/400\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.2329 - val_loss: 0.4130\n",
            "Epoch 267/400\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.2316 - val_loss: 0.4130\n",
            "Epoch 268/400\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.2308 - val_loss: 0.4130\n",
            "Epoch 269/400\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.2283 - val_loss: 0.4129\n",
            "Epoch 270/400\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.2299 - val_loss: 0.4129\n",
            "Epoch 271/400\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.2301 - val_loss: 0.4129\n",
            "Epoch 272/400\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.2304 - val_loss: 0.4129\n",
            "Epoch 273/400\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.2299 - val_loss: 0.4129\n",
            "Epoch 274/400\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.2279 - val_loss: 0.4128\n",
            "Epoch 275/400\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.2259 - val_loss: 0.4128\n",
            "Epoch 276/400\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.2231 - val_loss: 0.4128\n",
            "Epoch 277/400\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.2225 - val_loss: 0.4128\n",
            "Epoch 278/400\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.2203 - val_loss: 0.4128\n",
            "Epoch 279/400\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.2188 - val_loss: 0.4127\n",
            "Epoch 280/400\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.2179 - val_loss: 0.4127\n",
            "Epoch 281/400\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.2155 - val_loss: 0.4127\n",
            "Epoch 282/400\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.2157 - val_loss: 0.4127\n",
            "Epoch 283/400\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.2168 - val_loss: 0.4127\n",
            "Epoch 284/400\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.2168 - val_loss: 0.4127\n",
            "Epoch 285/400\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.2149 - val_loss: 0.4126\n",
            "Epoch 286/400\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.2126 - val_loss: 0.4126\n",
            "Epoch 287/400\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.2105 - val_loss: 0.4126\n",
            "Epoch 288/400\n",
            "2/2 [==============================] - 0s 74ms/step - loss: 0.2112 - val_loss: 0.4126\n",
            "Epoch 289/400\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.2093 - val_loss: 0.4126\n",
            "Epoch 290/400\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.2085 - val_loss: 0.4126\n",
            "Epoch 291/400\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.2079 - val_loss: 0.4125\n",
            "Epoch 292/400\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.2073 - val_loss: 0.4125\n",
            "Epoch 293/400\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.2068 - val_loss: 0.4125\n",
            "Epoch 294/400\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.2064 - val_loss: 0.4125\n",
            "Epoch 295/400\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.2060 - val_loss: 0.4125\n",
            "Epoch 296/400\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.2056 - val_loss: 0.4125\n",
            "Epoch 297/400\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.2051 - val_loss: 0.4125\n",
            "Epoch 298/400\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.2049 - val_loss: 0.4125\n",
            "Epoch 299/400\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.2047 - val_loss: 0.4125\n",
            "Epoch 300/400\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.2049 - val_loss: 0.4124\n",
            "Epoch 301/400\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.2056 - val_loss: 0.4124\n",
            "Epoch 302/400\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.2065 - val_loss: 0.4124\n",
            "Epoch 303/400\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 0.2055 - val_loss: 0.4124\n",
            "Epoch 304/400\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.2032 - val_loss: 0.4124\n",
            "Epoch 305/400\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.2025 - val_loss: 0.4124\n",
            "Epoch 306/400\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.2018 - val_loss: 0.4124\n",
            "Epoch 307/400\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.2015 - val_loss: 0.4124\n",
            "Epoch 308/400\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.2011 - val_loss: 0.4124\n",
            "Epoch 309/400\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.2009 - val_loss: 0.4124\n",
            "Epoch 310/400\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.2007 - val_loss: 0.4124\n",
            "Epoch 311/400\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.2005 - val_loss: 0.4124\n",
            "Epoch 312/400\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 0.2008 - val_loss: 0.4124\n",
            "Epoch 313/400\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.2004 - val_loss: 0.4124\n",
            "Epoch 314/400\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 0.1996 - val_loss: 0.4124\n",
            "Epoch 315/400\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.1994 - val_loss: 0.4124\n",
            "Epoch 316/400\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.1994 - val_loss: 0.4124\n",
            "Epoch 317/400\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.1988 - val_loss: 0.4124\n",
            "Epoch 318/400\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.1987 - val_loss: 0.4123\n",
            "Epoch 319/400\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.1989 - val_loss: 0.4123\n",
            "Epoch 320/400\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.1990 - val_loss: 0.4123\n",
            "Epoch 321/400\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.1990 - val_loss: 0.4123\n",
            "Epoch 322/400\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.1987 - val_loss: 0.4123\n",
            "Epoch 323/400\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.1988 - val_loss: 0.4123\n",
            "Epoch 324/400\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.1974 - val_loss: 0.4123\n",
            "Epoch 325/400\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.1976 - val_loss: 0.4123\n",
            "Epoch 326/400\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.1982 - val_loss: 0.4123\n",
            "Epoch 327/400\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.1987 - val_loss: 0.4123\n",
            "Epoch 328/400\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.1984 - val_loss: 0.4123\n",
            "Epoch 329/400\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 0.1981 - val_loss: 0.4123\n",
            "Epoch 330/400\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.1962 - val_loss: 0.4123\n",
            "Epoch 331/400\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.1953 - val_loss: 0.4123\n",
            "Epoch 332/400\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.1960 - val_loss: 0.4123\n",
            "Epoch 333/400\n",
            "2/2 [==============================] - 0s 80ms/step - loss: 0.1948 - val_loss: 0.4123\n",
            "Epoch 334/400\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.1945 - val_loss: 0.4122\n",
            "Epoch 335/400\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 0.1944 - val_loss: 0.4122\n",
            "Epoch 336/400\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.1943 - val_loss: 0.4122\n",
            "Epoch 337/400\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.1943 - val_loss: 0.4122\n",
            "Epoch 338/400\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.1939 - val_loss: 0.4122\n",
            "Epoch 339/400\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.1935 - val_loss: 0.4122\n",
            "Epoch 340/400\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.1934 - val_loss: 0.4122\n",
            "Epoch 341/400\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.1934 - val_loss: 0.4122\n",
            "Epoch 342/400\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.1936 - val_loss: 0.4122\n",
            "Epoch 343/400\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.1932 - val_loss: 0.4122\n",
            "Epoch 344/400\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 0.1934 - val_loss: 0.4122\n",
            "Epoch 345/400\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.1927 - val_loss: 0.4122\n",
            "Epoch 346/400\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.1926 - val_loss: 0.4122\n",
            "Epoch 347/400\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.1929 - val_loss: 0.4122\n",
            "Epoch 348/400\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.1936 - val_loss: 0.4122\n",
            "Epoch 349/400\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.1944 - val_loss: 0.4122\n",
            "Epoch 350/400\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.1940 - val_loss: 0.4122\n",
            "Epoch 351/400\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.1931 - val_loss: 0.4122\n",
            "Epoch 352/400\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.1925 - val_loss: 0.4122\n",
            "Epoch 353/400\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.1920 - val_loss: 0.4122\n",
            "Epoch 354/400\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.1918 - val_loss: 0.4122\n",
            "Epoch 355/400\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.1916 - val_loss: 0.4122\n",
            "Epoch 356/400\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.1915 - val_loss: 0.4122\n",
            "Epoch 357/400\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.1914 - val_loss: 0.4122\n",
            "Epoch 358/400\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.1913 - val_loss: 0.4122\n",
            "Epoch 359/400\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.1912 - val_loss: 0.4122\n",
            "Epoch 360/400\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.1913 - val_loss: 0.4122\n",
            "Epoch 361/400\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.1926 - val_loss: 0.4122\n",
            "Epoch 362/400\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.1918 - val_loss: 0.4122\n",
            "Epoch 363/400\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.1915 - val_loss: 0.4122\n",
            "Epoch 364/400\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.1909 - val_loss: 0.4122\n",
            "Epoch 365/400\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.1909 - val_loss: 0.4122\n",
            "Epoch 366/400\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.1908 - val_loss: 0.4122\n",
            "Epoch 367/400\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.1908 - val_loss: 0.4122\n",
            "Epoch 368/400\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.1913 - val_loss: 0.4122\n",
            "Epoch 369/400\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.1918 - val_loss: 0.4122\n",
            "Epoch 370/400\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.1922 - val_loss: 0.4122\n",
            "Epoch 371/400\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.1919 - val_loss: 0.4122\n",
            "Epoch 372/400\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.1911 - val_loss: 0.4121\n",
            "Epoch 373/400\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.1903 - val_loss: 0.4121\n",
            "Epoch 374/400\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.1904 - val_loss: 0.4121\n",
            "Epoch 375/400\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.1911 - val_loss: 0.4121\n",
            "Epoch 376/400\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.1923 - val_loss: 0.4121\n",
            "Epoch 377/400\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.1935 - val_loss: 0.4121\n",
            "Epoch 378/400\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.1941 - val_loss: 0.4121\n",
            "Epoch 379/400\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.1938 - val_loss: 0.4121\n",
            "Epoch 380/400\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.1931 - val_loss: 0.4121\n",
            "Epoch 381/400\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.1921 - val_loss: 0.4121\n",
            "Epoch 382/400\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.1912 - val_loss: 0.4121\n",
            "Epoch 383/400\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.1904 - val_loss: 0.4121\n",
            "Epoch 384/400\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.1901 - val_loss: 0.4121\n",
            "Epoch 385/400\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.1901 - val_loss: 0.4121\n",
            "Epoch 386/400\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.1903 - val_loss: 0.4121\n",
            "Epoch 387/400\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.1905 - val_loss: 0.4121\n",
            "Epoch 388/400\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.1907 - val_loss: 0.4121\n",
            "Epoch 389/400\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.1907 - val_loss: 0.4121\n",
            "Epoch 390/400\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.1909 - val_loss: 0.4121\n",
            "Epoch 391/400\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.1900 - val_loss: 0.4121\n",
            "Epoch 392/400\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.1900 - val_loss: 0.4121\n",
            "Epoch 393/400\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.1895 - val_loss: 0.4121\n",
            "Epoch 394/400\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.1904 - val_loss: 0.4121\n",
            "Epoch 395/400\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.1917 - val_loss: 0.4121\n",
            "Epoch 396/400\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.1930 - val_loss: 0.4121\n",
            "Epoch 397/400\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.1937 - val_loss: 0.4121\n",
            "Epoch 398/400\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.1936 - val_loss: 0.4121\n",
            "Epoch 399/400\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.1926 - val_loss: 0.4121\n",
            "Epoch 400/400\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.1911 - val_loss: 0.4121\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1/400\n",
            "1/1 [==============================] - 1s 831ms/step - loss: 1.3814 - val_loss: 1.8791\n",
            "Epoch 2/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 1.3790 - val_loss: 1.8745\n",
            "Epoch 3/400\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 1.3766 - val_loss: 1.8699\n",
            "Epoch 4/400\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 1.3742 - val_loss: 1.8654\n",
            "Epoch 5/400\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1.3719 - val_loss: 1.8609\n",
            "Epoch 6/400\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 1.3695 - val_loss: 1.8565\n",
            "Epoch 7/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 1.3671 - val_loss: 1.8522\n",
            "Epoch 8/400\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1.3647 - val_loss: 1.8479\n",
            "Epoch 9/400\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 1.3623 - val_loss: 1.8438\n",
            "Epoch 10/400\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 1.3599 - val_loss: 1.8397\n",
            "Epoch 11/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 1.3574 - val_loss: 1.8358\n",
            "Epoch 12/400\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 1.3550 - val_loss: 1.8319\n",
            "Epoch 13/400\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 1.3525 - val_loss: 1.8281\n",
            "Epoch 14/400\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 1.3501 - val_loss: 1.8244\n",
            "Epoch 15/400\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1.3476 - val_loss: 1.8207\n",
            "Epoch 16/400\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 1.3451 - val_loss: 1.8171\n",
            "Epoch 17/400\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 1.3426 - val_loss: 1.8136\n",
            "Epoch 18/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 1.3401 - val_loss: 1.8101\n",
            "Epoch 19/400\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 1.3375 - val_loss: 1.8067\n",
            "Epoch 20/400\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 1.3349 - val_loss: 1.8033\n",
            "Epoch 21/400\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 1.3323 - val_loss: 1.8000\n",
            "Epoch 22/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.3297 - val_loss: 1.7968\n",
            "Epoch 23/400\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 1.3270 - val_loss: 1.7936\n",
            "Epoch 24/400\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 1.3243 - val_loss: 1.7904\n",
            "Epoch 25/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 1.3216 - val_loss: 1.7873\n",
            "Epoch 26/400\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 1.3188 - val_loss: 1.7843\n",
            "Epoch 27/400\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 1.3160 - val_loss: 1.7813\n",
            "Epoch 28/400\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 1.3132 - val_loss: 1.7783\n",
            "Epoch 29/400\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 1.3103 - val_loss: 1.7754\n",
            "Epoch 30/400\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 1.3074 - val_loss: 1.7725\n",
            "Epoch 31/400\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 1.3044 - val_loss: 1.7697\n",
            "Epoch 32/400\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 1.3013 - val_loss: 1.7669\n",
            "Epoch 33/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 1.2982 - val_loss: 1.7642\n",
            "Epoch 34/400\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 1.2951 - val_loss: 1.7614\n",
            "Epoch 35/400\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 1.2918 - val_loss: 1.7588\n",
            "Epoch 36/400\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 1.2885 - val_loss: 1.7561\n",
            "Epoch 37/400\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1.2852 - val_loss: 1.7535\n",
            "Epoch 38/400\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 1.2817 - val_loss: 1.7509\n",
            "Epoch 39/400\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 1.2782 - val_loss: 1.7483\n",
            "Epoch 40/400\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 1.2746 - val_loss: 1.7458\n",
            "Epoch 41/400\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 1.2709 - val_loss: 1.7432\n",
            "Epoch 42/400\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 1.2671 - val_loss: 1.7407\n",
            "Epoch 43/400\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1.2633 - val_loss: 1.7382\n",
            "Epoch 44/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.2593 - val_loss: 1.7358\n",
            "Epoch 45/400\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 1.2553 - val_loss: 1.7333\n",
            "Epoch 46/400\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 1.2511 - val_loss: 1.7309\n",
            "Epoch 47/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 1.2468 - val_loss: 1.7285\n",
            "Epoch 48/400\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 1.2424 - val_loss: 1.7261\n",
            "Epoch 49/400\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 1.2379 - val_loss: 1.7237\n",
            "Epoch 50/400\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 1.2333 - val_loss: 1.7213\n",
            "Epoch 51/400\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.2286 - val_loss: 1.7189\n",
            "Epoch 52/400\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 1.2237 - val_loss: 1.7165\n",
            "Epoch 53/400\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 1.2187 - val_loss: 1.7142\n",
            "Epoch 54/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 1.2136 - val_loss: 1.7118\n",
            "Epoch 55/400\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 1.2083 - val_loss: 1.7094\n",
            "Epoch 56/400\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 1.2029 - val_loss: 1.7071\n",
            "Epoch 57/400\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 1.1973 - val_loss: 1.7047\n",
            "Epoch 58/400\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 1.1917 - val_loss: 1.7024\n",
            "Epoch 59/400\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 1.1858 - val_loss: 1.7000\n",
            "Epoch 60/400\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 1.1798 - val_loss: 1.6977\n",
            "Epoch 61/400\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 1.1737 - val_loss: 1.6953\n",
            "Epoch 62/400\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1.1674 - val_loss: 1.6930\n",
            "Epoch 63/400\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 1.1610 - val_loss: 1.6906\n",
            "Epoch 64/400\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1.1544 - val_loss: 1.6882\n",
            "Epoch 65/400\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 1.1476 - val_loss: 1.6858\n",
            "Epoch 66/400\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 1.1407 - val_loss: 1.6834\n",
            "Epoch 67/400\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 1.1337 - val_loss: 1.6810\n",
            "Epoch 68/400\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.1265 - val_loss: 1.6786\n",
            "Epoch 69/400\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 1.1191 - val_loss: 1.6761\n",
            "Epoch 70/400\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 1.1116 - val_loss: 1.6736\n",
            "Epoch 71/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.1040 - val_loss: 1.6711\n",
            "Epoch 72/400\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 1.0962 - val_loss: 1.6686\n",
            "Epoch 73/400\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1.0883 - val_loss: 1.6660\n",
            "Epoch 74/400\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 1.0803 - val_loss: 1.6634\n",
            "Epoch 75/400\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 1.0721 - val_loss: 1.6607\n",
            "Epoch 76/400\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1.0639 - val_loss: 1.6580\n",
            "Epoch 77/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 1.0555 - val_loss: 1.6552\n",
            "Epoch 78/400\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.0471 - val_loss: 1.6523\n",
            "Epoch 79/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 1.0386 - val_loss: 1.6494\n",
            "Epoch 80/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.0300 - val_loss: 1.6465\n",
            "Epoch 81/400\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 1.0214 - val_loss: 1.6434\n",
            "Epoch 82/400\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 1.0128 - val_loss: 1.6403\n",
            "Epoch 83/400\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 1.0042 - val_loss: 1.6370\n",
            "Epoch 84/400\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.9955 - val_loss: 1.6337\n",
            "Epoch 85/400\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.9869 - val_loss: 1.6303\n",
            "Epoch 86/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.9783 - val_loss: 1.6267\n",
            "Epoch 87/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.9698 - val_loss: 1.6231\n",
            "Epoch 88/400\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.9614 - val_loss: 1.6193\n",
            "Epoch 89/400\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.9531 - val_loss: 1.6153\n",
            "Epoch 90/400\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.9449 - val_loss: 1.6113\n",
            "Epoch 91/400\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.9369 - val_loss: 1.6070\n",
            "Epoch 92/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.9290 - val_loss: 1.6027\n",
            "Epoch 93/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.9213 - val_loss: 1.5981\n",
            "Epoch 94/400\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.9138 - val_loss: 1.5934\n",
            "Epoch 95/400\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.9066 - val_loss: 1.5885\n",
            "Epoch 96/400\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.8995 - val_loss: 1.5835\n",
            "Epoch 97/400\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.8926 - val_loss: 1.5782\n",
            "Epoch 98/400\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.8860 - val_loss: 1.5728\n",
            "Epoch 99/400\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.8796 - val_loss: 1.5672\n",
            "Epoch 100/400\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.8734 - val_loss: 1.5615\n",
            "Epoch 101/400\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.8675 - val_loss: 1.5556\n",
            "Epoch 102/400\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.8617 - val_loss: 1.5495\n",
            "Epoch 103/400\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.8561 - val_loss: 1.5433\n",
            "Epoch 104/400\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.8507 - val_loss: 1.5369\n",
            "Epoch 105/400\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.8455 - val_loss: 1.5304\n",
            "Epoch 106/400\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.8404 - val_loss: 1.5239\n",
            "Epoch 107/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.8354 - val_loss: 1.5172\n",
            "Epoch 108/400\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.8305 - val_loss: 1.5104\n",
            "Epoch 109/400\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.8257 - val_loss: 1.5036\n",
            "Epoch 110/400\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.8210 - val_loss: 1.4967\n",
            "Epoch 111/400\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.8163 - val_loss: 1.4898\n",
            "Epoch 112/400\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.8117 - val_loss: 1.4829\n",
            "Epoch 113/400\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.8071 - val_loss: 1.4760\n",
            "Epoch 114/400\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.8025 - val_loss: 1.4690\n",
            "Epoch 115/400\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.7980 - val_loss: 1.4621\n",
            "Epoch 116/400\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.7935 - val_loss: 1.4553\n",
            "Epoch 117/400\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.7890 - val_loss: 1.4485\n",
            "Epoch 118/400\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.7846 - val_loss: 1.4417\n",
            "Epoch 119/400\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.7801 - val_loss: 1.4350\n",
            "Epoch 120/400\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.7758 - val_loss: 1.4284\n",
            "Epoch 121/400\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.7714 - val_loss: 1.4218\n",
            "Epoch 122/400\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.7672 - val_loss: 1.4154\n",
            "Epoch 123/400\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.7629 - val_loss: 1.4090\n",
            "Epoch 124/400\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.7587 - val_loss: 1.4027\n",
            "Epoch 125/400\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.7546 - val_loss: 1.3965\n",
            "Epoch 126/400\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.7505 - val_loss: 1.3904\n",
            "Epoch 127/400\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.7465 - val_loss: 1.3845\n",
            "Epoch 128/400\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.7425 - val_loss: 1.3786\n",
            "Epoch 129/400\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.7386 - val_loss: 1.3728\n",
            "Epoch 130/400\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.7347 - val_loss: 1.3671\n",
            "Epoch 131/400\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.7309 - val_loss: 1.3615\n",
            "Epoch 132/400\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.7271 - val_loss: 1.3561\n",
            "Epoch 133/400\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.7234 - val_loss: 1.3507\n",
            "Epoch 134/400\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.7197 - val_loss: 1.3454\n",
            "Epoch 135/400\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.7160 - val_loss: 1.3401\n",
            "Epoch 136/400\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.7123 - val_loss: 1.3350\n",
            "Epoch 137/400\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.7087 - val_loss: 1.3299\n",
            "Epoch 138/400\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.7051 - val_loss: 1.3250\n",
            "Epoch 139/400\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 0.7016 - val_loss: 1.3201\n",
            "Epoch 140/400\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.6981 - val_loss: 1.3152\n",
            "Epoch 141/400\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.6946 - val_loss: 1.3104\n",
            "Epoch 142/400\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.6911 - val_loss: 1.3057\n",
            "Epoch 143/400\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.6876 - val_loss: 1.3010\n",
            "Epoch 144/400\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.6842 - val_loss: 1.2964\n",
            "Epoch 145/400\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.6808 - val_loss: 1.2918\n",
            "Epoch 146/400\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.6775 - val_loss: 1.2873\n",
            "Epoch 147/400\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.6741 - val_loss: 1.2828\n",
            "Epoch 148/400\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.6708 - val_loss: 1.2784\n",
            "Epoch 149/400\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.6675 - val_loss: 1.2739\n",
            "Epoch 150/400\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.6642 - val_loss: 1.2696\n",
            "Epoch 151/400\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.6610 - val_loss: 1.2652\n",
            "Epoch 152/400\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.6578 - val_loss: 1.2609\n",
            "Epoch 153/400\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.6546 - val_loss: 1.2566\n",
            "Epoch 154/400\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.6514 - val_loss: 1.2523\n",
            "Epoch 155/400\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.6483 - val_loss: 1.2480\n",
            "Epoch 156/400\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.6452 - val_loss: 1.2438\n",
            "Epoch 157/400\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.6420 - val_loss: 1.2396\n",
            "Epoch 158/400\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.6390 - val_loss: 1.2354\n",
            "Epoch 159/400\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.6359 - val_loss: 1.2312\n",
            "Epoch 160/400\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.6329 - val_loss: 1.2271\n",
            "Epoch 161/400\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.6298 - val_loss: 1.2229\n",
            "Epoch 162/400\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.6268 - val_loss: 1.2188\n",
            "Epoch 163/400\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.6239 - val_loss: 1.2147\n",
            "Epoch 164/400\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.6209 - val_loss: 1.2106\n",
            "Epoch 165/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.6179 - val_loss: 1.2066\n",
            "Epoch 166/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.6150 - val_loss: 1.2025\n",
            "Epoch 167/400\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.6121 - val_loss: 1.1985\n",
            "Epoch 168/400\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.6092 - val_loss: 1.1945\n",
            "Epoch 169/400\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.6063 - val_loss: 1.1905\n",
            "Epoch 170/400\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.6034 - val_loss: 1.1865\n",
            "Epoch 171/400\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.6006 - val_loss: 1.1825\n",
            "Epoch 172/400\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5978 - val_loss: 1.1786\n",
            "Epoch 173/400\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.5950 - val_loss: 1.1746\n",
            "Epoch 174/400\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.5922 - val_loss: 1.1707\n",
            "Epoch 175/400\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.5894 - val_loss: 1.1668\n",
            "Epoch 176/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.5866 - val_loss: 1.1629\n",
            "Epoch 177/400\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.5839 - val_loss: 1.1590\n",
            "Epoch 178/400\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.5811 - val_loss: 1.1552\n",
            "Epoch 179/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.5784 - val_loss: 1.1513\n",
            "Epoch 180/400\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.5757 - val_loss: 1.1474\n",
            "Epoch 181/400\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.5730 - val_loss: 1.1436\n",
            "Epoch 182/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5703 - val_loss: 1.1398\n",
            "Epoch 183/400\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.5676 - val_loss: 1.1360\n",
            "Epoch 184/400\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5650 - val_loss: 1.1321\n",
            "Epoch 185/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5623 - val_loss: 1.1283\n",
            "Epoch 186/400\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.5597 - val_loss: 1.1245\n",
            "Epoch 187/400\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.5570 - val_loss: 1.1207\n",
            "Epoch 188/400\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.5544 - val_loss: 1.1169\n",
            "Epoch 189/400\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.5518 - val_loss: 1.1131\n",
            "Epoch 190/400\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.5493 - val_loss: 1.1093\n",
            "Epoch 191/400\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.5467 - val_loss: 1.1055\n",
            "Epoch 192/400\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.5441 - val_loss: 1.1018\n",
            "Epoch 193/400\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.5416 - val_loss: 1.0980\n",
            "Epoch 194/400\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.5390 - val_loss: 1.0942\n",
            "Epoch 195/400\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.5365 - val_loss: 1.0904\n",
            "Epoch 196/400\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.5340 - val_loss: 1.0866\n",
            "Epoch 197/400\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5315 - val_loss: 1.0828\n",
            "Epoch 198/400\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5290 - val_loss: 1.0791\n",
            "Epoch 199/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5265 - val_loss: 1.0753\n",
            "Epoch 200/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5240 - val_loss: 1.0715\n",
            "Epoch 201/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.5215 - val_loss: 1.0677\n",
            "Epoch 202/400\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.5191 - val_loss: 1.0639\n",
            "Epoch 203/400\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.5166 - val_loss: 1.0602\n",
            "Epoch 204/400\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.5142 - val_loss: 1.0564\n",
            "Epoch 205/400\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.5117 - val_loss: 1.0526\n",
            "Epoch 206/400\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.5093 - val_loss: 1.0488\n",
            "Epoch 207/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.5069 - val_loss: 1.0450\n",
            "Epoch 208/400\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.5045 - val_loss: 1.0413\n",
            "Epoch 209/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5021 - val_loss: 1.0375\n",
            "Epoch 210/400\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.4997 - val_loss: 1.0337\n",
            "Epoch 211/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.4974 - val_loss: 1.0299\n",
            "Epoch 212/400\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.4950 - val_loss: 1.0262\n",
            "Epoch 213/400\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.4926 - val_loss: 1.0224\n",
            "Epoch 214/400\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.4903 - val_loss: 1.0186\n",
            "Epoch 215/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.4879 - val_loss: 1.0148\n",
            "Epoch 216/400\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.4856 - val_loss: 1.0111\n",
            "Epoch 217/400\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.4833 - val_loss: 1.0073\n",
            "Epoch 218/400\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.4810 - val_loss: 1.0035\n",
            "Epoch 219/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.4787 - val_loss: 0.9997\n",
            "Epoch 220/400\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.4764 - val_loss: 0.9959\n",
            "Epoch 221/400\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.4741 - val_loss: 0.9922\n",
            "Epoch 222/400\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.4718 - val_loss: 0.9884\n",
            "Epoch 223/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.4695 - val_loss: 0.9846\n",
            "Epoch 224/400\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.4673 - val_loss: 0.9808\n",
            "Epoch 225/400\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.4650 - val_loss: 0.9771\n",
            "Epoch 226/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.4628 - val_loss: 0.9733\n",
            "Epoch 227/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.4605 - val_loss: 0.9695\n",
            "Epoch 228/400\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.4583 - val_loss: 0.9658\n",
            "Epoch 229/400\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.4561 - val_loss: 0.9620\n",
            "Epoch 230/400\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.4539 - val_loss: 0.9582\n",
            "Epoch 231/400\n",
            "1/1 [==============================] - 0s 237ms/step - loss: 0.4517 - val_loss: 0.9545\n",
            "Epoch 232/400\n",
            "1/1 [==============================] - 0s 268ms/step - loss: 0.4495 - val_loss: 0.9507\n",
            "Epoch 233/400\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.4473 - val_loss: 0.9469\n",
            "Epoch 234/400\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.4451 - val_loss: 0.9432\n",
            "Epoch 235/400\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.4429 - val_loss: 0.9394\n",
            "Epoch 236/400\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.4408 - val_loss: 0.9357\n",
            "Epoch 237/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.4386 - val_loss: 0.9319\n",
            "Epoch 238/400\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.4365 - val_loss: 0.9282\n",
            "Epoch 239/400\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.4344 - val_loss: 0.9245\n",
            "Epoch 240/400\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.4322 - val_loss: 0.9207\n",
            "Epoch 241/400\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.4301 - val_loss: 0.9170\n",
            "Epoch 242/400\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.4280 - val_loss: 0.9133\n",
            "Epoch 243/400\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 0.4259 - val_loss: 0.9096\n",
            "Epoch 244/400\n",
            "1/1 [==============================] - 0s 218ms/step - loss: 0.4238 - val_loss: 0.9058\n",
            "Epoch 245/400\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.4217 - val_loss: 0.9021\n",
            "Epoch 246/400\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.4197 - val_loss: 0.8984\n",
            "Epoch 247/400\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.4176 - val_loss: 0.8948\n",
            "Epoch 248/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.4155 - val_loss: 0.8911\n",
            "Epoch 249/400\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.4135 - val_loss: 0.8874\n",
            "Epoch 250/400\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.4115 - val_loss: 0.8837\n",
            "Epoch 251/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.4094 - val_loss: 0.8801\n",
            "Epoch 252/400\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.4074 - val_loss: 0.8764\n",
            "Epoch 253/400\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.4054 - val_loss: 0.8728\n",
            "Epoch 254/400\n",
            "1/1 [==============================] - 0s 239ms/step - loss: 0.4034 - val_loss: 0.8691\n",
            "Epoch 255/400\n",
            "1/1 [==============================] - 0s 281ms/step - loss: 0.4014 - val_loss: 0.8655\n",
            "Epoch 256/400\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.3994 - val_loss: 0.8619\n",
            "Epoch 257/400\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 0.3975 - val_loss: 0.8583\n",
            "Epoch 258/400\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.3955 - val_loss: 0.8547\n",
            "Epoch 259/400\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.3936 - val_loss: 0.8511\n",
            "Epoch 260/400\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.3916 - val_loss: 0.8476\n",
            "Epoch 261/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.3897 - val_loss: 0.8440\n",
            "Epoch 262/400\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.3878 - val_loss: 0.8405\n",
            "Epoch 263/400\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.3859 - val_loss: 0.8369\n",
            "Epoch 264/400\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.3840 - val_loss: 0.8334\n",
            "Epoch 265/400\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.3821 - val_loss: 0.8299\n",
            "Epoch 266/400\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.3803 - val_loss: 0.8264\n",
            "Epoch 267/400\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.3784 - val_loss: 0.8229\n",
            "Epoch 268/400\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.3765 - val_loss: 0.8195\n",
            "Epoch 269/400\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.3747 - val_loss: 0.8160\n",
            "Epoch 270/400\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.3729 - val_loss: 0.8126\n",
            "Epoch 271/400\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.3711 - val_loss: 0.8092\n",
            "Epoch 272/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.3693 - val_loss: 0.8057\n",
            "Epoch 273/400\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.3675 - val_loss: 0.8024\n",
            "Epoch 274/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.3657 - val_loss: 0.7990\n",
            "Epoch 275/400\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.3639 - val_loss: 0.7956\n",
            "Epoch 276/400\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.3622 - val_loss: 0.7923\n",
            "Epoch 277/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.3604 - val_loss: 0.7890\n",
            "Epoch 278/400\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.3587 - val_loss: 0.7856\n",
            "Epoch 279/400\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.3570 - val_loss: 0.7824\n",
            "Epoch 280/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.3552 - val_loss: 0.7791\n",
            "Epoch 281/400\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.3535 - val_loss: 0.7758\n",
            "Epoch 282/400\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.3519 - val_loss: 0.7726\n",
            "Epoch 283/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.3502 - val_loss: 0.7694\n",
            "Epoch 284/400\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.3485 - val_loss: 0.7662\n",
            "Epoch 285/400\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.3469 - val_loss: 0.7630\n",
            "Epoch 286/400\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.3452 - val_loss: 0.7598\n",
            "Epoch 287/400\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.3436 - val_loss: 0.7567\n",
            "Epoch 288/400\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.3420 - val_loss: 0.7536\n",
            "Epoch 289/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.3404 - val_loss: 0.7505\n",
            "Epoch 290/400\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.3388 - val_loss: 0.7474\n",
            "Epoch 291/400\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.3373 - val_loss: 0.7444\n",
            "Epoch 292/400\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.3357 - val_loss: 0.7413\n",
            "Epoch 293/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.3341 - val_loss: 0.7383\n",
            "Epoch 294/400\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.3326 - val_loss: 0.7354\n",
            "Epoch 295/400\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.3311 - val_loss: 0.7324\n",
            "Epoch 296/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.3296 - val_loss: 0.7295\n",
            "Epoch 297/400\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.3281 - val_loss: 0.7265\n",
            "Epoch 298/400\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.3266 - val_loss: 0.7237\n",
            "Epoch 299/400\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.3251 - val_loss: 0.7208\n",
            "Epoch 300/400\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.3237 - val_loss: 0.7180\n",
            "Epoch 301/400\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.3222 - val_loss: 0.7151\n",
            "Epoch 302/400\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.3208 - val_loss: 0.7124\n",
            "Epoch 303/400\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.3194 - val_loss: 0.7096\n",
            "Epoch 304/400\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.3180 - val_loss: 0.7069\n",
            "Epoch 305/400\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.3166 - val_loss: 0.7041\n",
            "Epoch 306/400\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.3152 - val_loss: 0.7015\n",
            "Epoch 307/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.3139 - val_loss: 0.6988\n",
            "Epoch 308/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.3125 - val_loss: 0.6962\n",
            "Epoch 309/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.3112 - val_loss: 0.6936\n",
            "Epoch 310/400\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.3099 - val_loss: 0.6910\n",
            "Epoch 311/400\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.3086 - val_loss: 0.6884\n",
            "Epoch 312/400\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.3073 - val_loss: 0.6859\n",
            "Epoch 313/400\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.3060 - val_loss: 0.6834\n",
            "Epoch 314/400\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.3047 - val_loss: 0.6809\n",
            "Epoch 315/400\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.3035 - val_loss: 0.6785\n",
            "Epoch 316/400\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.3023 - val_loss: 0.6761\n",
            "Epoch 317/400\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.3010 - val_loss: 0.6737\n",
            "Epoch 318/400\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.2998 - val_loss: 0.6713\n",
            "Epoch 319/400\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.2986 - val_loss: 0.6690\n",
            "Epoch 320/400\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.2974 - val_loss: 0.6667\n",
            "Epoch 321/400\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.2963 - val_loss: 0.6644\n",
            "Epoch 322/400\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.2951 - val_loss: 0.6622\n",
            "Epoch 323/400\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.2940 - val_loss: 0.6600\n",
            "Epoch 324/400\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.2928 - val_loss: 0.6578\n",
            "Epoch 325/400\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.2917 - val_loss: 0.6556\n",
            "Epoch 326/400\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.2906 - val_loss: 0.6535\n",
            "Epoch 327/400\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.2895 - val_loss: 0.6514\n",
            "Epoch 328/400\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.2885 - val_loss: 0.6493\n",
            "Epoch 329/400\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.2874 - val_loss: 0.6473\n",
            "Epoch 330/400\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.2863 - val_loss: 0.6452\n",
            "Epoch 331/400\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.2853 - val_loss: 0.6433\n",
            "Epoch 332/400\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.2843 - val_loss: 0.6413\n",
            "Epoch 333/400\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.2833 - val_loss: 0.6394\n",
            "Epoch 334/400\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.2823 - val_loss: 0.6374\n",
            "Epoch 335/400\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.2813 - val_loss: 0.6356\n",
            "Epoch 336/400\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 0.2803 - val_loss: 0.6337\n",
            "Epoch 337/400\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.2794 - val_loss: 0.6319\n",
            "Epoch 338/400\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.2784 - val_loss: 0.6301\n",
            "Epoch 339/400\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.2775 - val_loss: 0.6283\n",
            "Epoch 340/400\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.2765 - val_loss: 0.6266\n",
            "Epoch 341/400\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.2756 - val_loss: 0.6248\n",
            "Epoch 342/400\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.2747 - val_loss: 0.6231\n",
            "Epoch 343/400\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.2738 - val_loss: 0.6215\n",
            "Epoch 344/400\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.2730 - val_loss: 0.6198\n",
            "Epoch 345/400\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.2721 - val_loss: 0.6182\n",
            "Epoch 346/400\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.2713 - val_loss: 0.6166\n",
            "Epoch 347/400\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.2704 - val_loss: 0.6151\n",
            "Epoch 348/400\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.2696 - val_loss: 0.6135\n",
            "Epoch 349/400\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.2688 - val_loss: 0.6120\n",
            "Epoch 350/400\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.2680 - val_loss: 0.6105\n",
            "Epoch 351/400\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.2672 - val_loss: 0.6090\n",
            "Epoch 352/400\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.2664 - val_loss: 0.6076\n",
            "Epoch 353/400\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.2656 - val_loss: 0.6062\n",
            "Epoch 354/400\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.2649 - val_loss: 0.6048\n",
            "Epoch 355/400\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 0.2641 - val_loss: 0.6034\n",
            "Epoch 356/400\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.2634 - val_loss: 0.6020\n",
            "Epoch 357/400\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.2626 - val_loss: 0.6007\n",
            "Epoch 358/400\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.2619 - val_loss: 0.5994\n",
            "Epoch 359/400\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.2612 - val_loss: 0.5981\n",
            "Epoch 360/400\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.2605 - val_loss: 0.5968\n",
            "Epoch 361/400\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.2598 - val_loss: 0.5956\n",
            "Epoch 362/400\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.2591 - val_loss: 0.5944\n",
            "Epoch 363/400\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.2585 - val_loss: 0.5932\n",
            "Epoch 364/400\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.2578 - val_loss: 0.5920\n",
            "Epoch 365/400\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.2572 - val_loss: 0.5908\n",
            "Epoch 366/400\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.2565 - val_loss: 0.5897\n",
            "Epoch 367/400\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.2559 - val_loss: 0.5886\n",
            "Epoch 368/400\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.2553 - val_loss: 0.5874\n",
            "Epoch 369/400\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.2547 - val_loss: 0.5864\n",
            "Epoch 370/400\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.2541 - val_loss: 0.5853\n",
            "Epoch 371/400\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.2535 - val_loss: 0.5842\n",
            "Epoch 372/400\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.2529 - val_loss: 0.5832\n",
            "Epoch 373/400\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.2523 - val_loss: 0.5822\n",
            "Epoch 374/400\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.2517 - val_loss: 0.5812\n",
            "Epoch 375/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.2512 - val_loss: 0.5802\n",
            "Epoch 376/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.2506 - val_loss: 0.5793\n",
            "Epoch 377/400\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.2501 - val_loss: 0.5783\n",
            "Epoch 378/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.2495 - val_loss: 0.5774\n",
            "Epoch 379/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.2490 - val_loss: 0.5765\n",
            "Epoch 380/400\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.2485 - val_loss: 0.5756\n",
            "Epoch 381/400\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.2480 - val_loss: 0.5747\n",
            "Epoch 382/400\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.2475 - val_loss: 0.5738\n",
            "Epoch 383/400\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.2470 - val_loss: 0.5730\n",
            "Epoch 384/400\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.2465 - val_loss: 0.5721\n",
            "Epoch 385/400\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.2460 - val_loss: 0.5713\n",
            "Epoch 386/400\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.2455 - val_loss: 0.5705\n",
            "Epoch 387/400\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.2451 - val_loss: 0.5697\n",
            "Epoch 388/400\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.2446 - val_loss: 0.5689\n",
            "Epoch 389/400\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.2441 - val_loss: 0.5681\n",
            "Epoch 390/400\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.2437 - val_loss: 0.5674\n",
            "Epoch 391/400\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.2433 - val_loss: 0.5666\n",
            "Epoch 392/400\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.2428 - val_loss: 0.5659\n",
            "Epoch 393/400\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.2424 - val_loss: 0.5652\n",
            "Epoch 394/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.2420 - val_loss: 0.5645\n",
            "Epoch 395/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.2415 - val_loss: 0.5638\n",
            "Epoch 396/400\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.2411 - val_loss: 0.5631\n",
            "Epoch 397/400\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.2407 - val_loss: 0.5624\n",
            "Epoch 398/400\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.2403 - val_loss: 0.5618\n",
            "Epoch 399/400\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.2399 - val_loss: 0.5611\n",
            "Epoch 400/400\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.2395 - val_loss: 0.5605\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 1/400\n",
            "1/1 [==============================] - 1s 999ms/step - loss: 1.5199 - val_loss: 0.9666\n",
            "Epoch 2/400\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 1.5182 - val_loss: 0.9638\n",
            "Epoch 3/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 1.5165 - val_loss: 0.9610\n",
            "Epoch 4/400\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 1.5148 - val_loss: 0.9582\n",
            "Epoch 5/400\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1.5131 - val_loss: 0.9554\n",
            "Epoch 6/400\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1.5114 - val_loss: 0.9526\n",
            "Epoch 7/400\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 1.5098 - val_loss: 0.9499\n",
            "Epoch 8/400\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 1.5081 - val_loss: 0.9471\n",
            "Epoch 9/400\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 1.5064 - val_loss: 0.9443\n",
            "Epoch 10/400\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 1.5047 - val_loss: 0.9415\n",
            "Epoch 11/400\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 1.5030 - val_loss: 0.9388\n",
            "Epoch 12/400\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 1.5013 - val_loss: 0.9360\n",
            "Epoch 13/400\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 1.4996 - val_loss: 0.9332\n",
            "Epoch 14/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 1.4980 - val_loss: 0.9305\n",
            "Epoch 15/400\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 1.4963 - val_loss: 0.9277\n",
            "Epoch 16/400\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 1.4946 - val_loss: 0.9249\n",
            "Epoch 17/400\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 1.4929 - val_loss: 0.9221\n",
            "Epoch 18/400\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 1.4911 - val_loss: 0.9193\n",
            "Epoch 19/400\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 1.4894 - val_loss: 0.9166\n",
            "Epoch 20/400\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 1.4877 - val_loss: 0.9138\n",
            "Epoch 21/400\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 1.4860 - val_loss: 0.9110\n",
            "Epoch 22/400\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1.4843 - val_loss: 0.9082\n",
            "Epoch 23/400\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1.4825 - val_loss: 0.9054\n",
            "Epoch 24/400\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 1.4808 - val_loss: 0.9026\n",
            "Epoch 25/400\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1.4790 - val_loss: 0.8998\n",
            "Epoch 26/400\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1.4772 - val_loss: 0.8969\n",
            "Epoch 27/400\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 1.4755 - val_loss: 0.8941\n",
            "Epoch 28/400\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 1.4737 - val_loss: 0.8913\n",
            "Epoch 29/400\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 1.4719 - val_loss: 0.8885\n",
            "Epoch 30/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.4701 - val_loss: 0.8856\n",
            "Epoch 31/400\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 1.4682 - val_loss: 0.8828\n",
            "Epoch 32/400\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1.4664 - val_loss: 0.8799\n",
            "Epoch 33/400\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 1.4646 - val_loss: 0.8770\n",
            "Epoch 34/400\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1.4627 - val_loss: 0.8742\n",
            "Epoch 35/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 1.4608 - val_loss: 0.8713\n",
            "Epoch 36/400\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1.4589 - val_loss: 0.8684\n",
            "Epoch 37/400\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 1.4570 - val_loss: 0.8655\n",
            "Epoch 38/400\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 1.4551 - val_loss: 0.8626\n",
            "Epoch 39/400\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 1.4532 - val_loss: 0.8596\n",
            "Epoch 40/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 1.4512 - val_loss: 0.8567\n",
            "Epoch 41/400\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 1.4493 - val_loss: 0.8538\n",
            "Epoch 42/400\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 1.4473 - val_loss: 0.8508\n",
            "Epoch 43/400\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 1.4453 - val_loss: 0.8478\n",
            "Epoch 44/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.4432 - val_loss: 0.8449\n",
            "Epoch 45/400\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 1.4412 - val_loss: 0.8419\n",
            "Epoch 46/400\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 1.4391 - val_loss: 0.8389\n",
            "Epoch 47/400\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 1.4371 - val_loss: 0.8359\n",
            "Epoch 48/400\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 1.4350 - val_loss: 0.8328\n",
            "Epoch 49/400\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 1.4328 - val_loss: 0.8298\n",
            "Epoch 50/400\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 1.4307 - val_loss: 0.8267\n",
            "Epoch 51/400\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 1.4285 - val_loss: 0.8237\n",
            "Epoch 52/400\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1.4263 - val_loss: 0.8206\n",
            "Epoch 53/400\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 1.4241 - val_loss: 0.8175\n",
            "Epoch 54/400\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1.4219 - val_loss: 0.8144\n",
            "Epoch 55/400\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 1.4196 - val_loss: 0.8113\n",
            "Epoch 56/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 1.4174 - val_loss: 0.8082\n",
            "Epoch 57/400\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 1.4150 - val_loss: 0.8050\n",
            "Epoch 58/400\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 1.4127 - val_loss: 0.8019\n",
            "Epoch 59/400\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 1.4104 - val_loss: 0.7987\n",
            "Epoch 60/400\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1.4080 - val_loss: 0.7955\n",
            "Epoch 61/400\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 1.4055 - val_loss: 0.7923\n",
            "Epoch 62/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 1.4031 - val_loss: 0.7891\n",
            "Epoch 63/400\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 1.4006 - val_loss: 0.7858\n",
            "Epoch 64/400\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 1.3981 - val_loss: 0.7826\n",
            "Epoch 65/400\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 1.3956 - val_loss: 0.7793\n",
            "Epoch 66/400\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 1.3930 - val_loss: 0.7761\n",
            "Epoch 67/400\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 1.3904 - val_loss: 0.7728\n",
            "Epoch 68/400\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 1.3878 - val_loss: 0.7695\n",
            "Epoch 69/400\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 1.3851 - val_loss: 0.7661\n",
            "Epoch 70/400\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 1.3824 - val_loss: 0.7628\n",
            "Epoch 71/400\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 1.3797 - val_loss: 0.7595\n",
            "Epoch 72/400\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 1.3769 - val_loss: 0.7561\n",
            "Epoch 73/400\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 1.3741 - val_loss: 0.7527\n",
            "Epoch 74/400\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 1.3713 - val_loss: 0.7493\n",
            "Epoch 75/400\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 1.3684 - val_loss: 0.7459\n",
            "Epoch 76/400\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 1.3655 - val_loss: 0.7425\n",
            "Epoch 77/400\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 1.3625 - val_loss: 0.7391\n",
            "Epoch 78/400\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 1.3595 - val_loss: 0.7357\n",
            "Epoch 79/400\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 1.3565 - val_loss: 0.7322\n",
            "Epoch 80/400\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 1.3534 - val_loss: 0.7288\n",
            "Epoch 81/400\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 1.3503 - val_loss: 0.7253\n",
            "Epoch 82/400\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 1.3471 - val_loss: 0.7218\n",
            "Epoch 83/400\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 1.3439 - val_loss: 0.7184\n",
            "Epoch 84/400\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 1.3406 - val_loss: 0.7149\n",
            "Epoch 85/400\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 1.3373 - val_loss: 0.7114\n",
            "Epoch 86/400\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 1.3339 - val_loss: 0.7079\n",
            "Epoch 87/400\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 1.3305 - val_loss: 0.7044\n",
            "Epoch 88/400\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 1.3271 - val_loss: 0.7008\n",
            "Epoch 89/400\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 1.3236 - val_loss: 0.6973\n",
            "Epoch 90/400\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 1.3200 - val_loss: 0.6938\n",
            "Epoch 91/400\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 1.3164 - val_loss: 0.6902\n",
            "Epoch 92/400\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 1.3127 - val_loss: 0.6867\n",
            "Epoch 93/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 1.3090 - val_loss: 0.6831\n",
            "Epoch 94/400\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 1.3052 - val_loss: 0.6795\n",
            "Epoch 95/400\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 1.3014 - val_loss: 0.6760\n",
            "Epoch 96/400\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 1.2975 - val_loss: 0.6724\n",
            "Epoch 97/400\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 1.2935 - val_loss: 0.6688\n",
            "Epoch 98/400\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 1.2895 - val_loss: 0.6652\n",
            "Epoch 99/400\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 1.2854 - val_loss: 0.6616\n",
            "Epoch 100/400\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 1.2813 - val_loss: 0.6580\n",
            "Epoch 101/400\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 1.2771 - val_loss: 0.6543\n",
            "Epoch 102/400\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 1.2729 - val_loss: 0.6507\n",
            "Epoch 103/400\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 1.2686 - val_loss: 0.6471\n",
            "Epoch 104/400\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 1.2642 - val_loss: 0.6434\n",
            "Epoch 105/400\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 1.2597 - val_loss: 0.6397\n",
            "Epoch 106/400\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 1.2552 - val_loss: 0.6361\n",
            "Epoch 107/400\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 1.2507 - val_loss: 0.6324\n",
            "Epoch 108/400\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 1.2460 - val_loss: 0.6287\n",
            "Epoch 109/400\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 1.2413 - val_loss: 0.6250\n",
            "Epoch 110/400\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 1.2366 - val_loss: 0.6213\n",
            "Epoch 111/400\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 1.2317 - val_loss: 0.6176\n",
            "Epoch 112/400\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 1.2268 - val_loss: 0.6139\n",
            "Epoch 113/400\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 1.2219 - val_loss: 0.6102\n",
            "Epoch 114/400\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 1.2168 - val_loss: 0.6064\n",
            "Epoch 115/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.2118 - val_loss: 0.6027\n",
            "Epoch 116/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.2066 - val_loss: 0.5990\n",
            "Epoch 117/400\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 1.2014 - val_loss: 0.5952\n",
            "Epoch 118/400\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1.1961 - val_loss: 0.5915\n",
            "Epoch 119/400\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 1.1908 - val_loss: 0.5877\n",
            "Epoch 120/400\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 1.1854 - val_loss: 0.5839\n",
            "Epoch 121/400\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 1.1800 - val_loss: 0.5802\n",
            "Epoch 122/400\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 1.1744 - val_loss: 0.5764\n",
            "Epoch 123/400\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 1.1689 - val_loss: 0.5726\n",
            "Epoch 124/400\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 1.1633 - val_loss: 0.5689\n",
            "Epoch 125/400\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1.1576 - val_loss: 0.5651\n",
            "Epoch 126/400\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 1.1519 - val_loss: 0.5614\n",
            "Epoch 127/400\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1.1462 - val_loss: 0.5576\n",
            "Epoch 128/400\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 1.1404 - val_loss: 0.5539\n",
            "Epoch 129/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.1345 - val_loss: 0.5501\n",
            "Epoch 130/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.1286 - val_loss: 0.5464\n",
            "Epoch 131/400\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 1.1227 - val_loss: 0.5427\n",
            "Epoch 132/400\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 1.1168 - val_loss: 0.5390\n",
            "Epoch 133/400\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 1.1108 - val_loss: 0.5353\n",
            "Epoch 134/400\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 1.1048 - val_loss: 0.5316\n",
            "Epoch 135/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 1.0988 - val_loss: 0.5280\n",
            "Epoch 136/400\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 1.0927 - val_loss: 0.5244\n",
            "Epoch 137/400\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 1.0867 - val_loss: 0.5208\n",
            "Epoch 138/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 1.0806 - val_loss: 0.5172\n",
            "Epoch 139/400\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1.0745 - val_loss: 0.5137\n",
            "Epoch 140/400\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 1.0684 - val_loss: 0.5102\n",
            "Epoch 141/400\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 1.0624 - val_loss: 0.5067\n",
            "Epoch 142/400\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 1.0563 - val_loss: 0.5033\n",
            "Epoch 143/400\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1.0502 - val_loss: 0.4999\n",
            "Epoch 144/400\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 1.0441 - val_loss: 0.4966\n",
            "Epoch 145/400\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 1.0380 - val_loss: 0.4933\n",
            "Epoch 146/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 1.0320 - val_loss: 0.4901\n",
            "Epoch 147/400\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 1.0259 - val_loss: 0.4869\n",
            "Epoch 148/400\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 1.0199 - val_loss: 0.4838\n",
            "Epoch 149/400\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 1.0139 - val_loss: 0.4807\n",
            "Epoch 150/400\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 1.0079 - val_loss: 0.4777\n",
            "Epoch 151/400\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 1.0019 - val_loss: 0.4748\n",
            "Epoch 152/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.9960 - val_loss: 0.4719\n",
            "Epoch 153/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.9900 - val_loss: 0.4691\n",
            "Epoch 154/400\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.9841 - val_loss: 0.4664\n",
            "Epoch 155/400\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.9783 - val_loss: 0.4638\n",
            "Epoch 156/400\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.9724 - val_loss: 0.4612\n",
            "Epoch 157/400\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.9666 - val_loss: 0.4587\n",
            "Epoch 158/400\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.9608 - val_loss: 0.4563\n",
            "Epoch 159/400\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.9550 - val_loss: 0.4540\n",
            "Epoch 160/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.9493 - val_loss: 0.4517\n",
            "Epoch 161/400\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.9436 - val_loss: 0.4495\n",
            "Epoch 162/400\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.9379 - val_loss: 0.4474\n",
            "Epoch 163/400\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.9322 - val_loss: 0.4454\n",
            "Epoch 164/400\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.9266 - val_loss: 0.4435\n",
            "Epoch 165/400\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.9210 - val_loss: 0.4416\n",
            "Epoch 166/400\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.9154 - val_loss: 0.4399\n",
            "Epoch 167/400\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.9098 - val_loss: 0.4382\n",
            "Epoch 168/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.9043 - val_loss: 0.4366\n",
            "Epoch 169/400\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.8988 - val_loss: 0.4350\n",
            "Epoch 170/400\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.8933 - val_loss: 0.4335\n",
            "Epoch 171/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.8879 - val_loss: 0.4321\n",
            "Epoch 172/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.8824 - val_loss: 0.4308\n",
            "Epoch 173/400\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.8770 - val_loss: 0.4295\n",
            "Epoch 174/400\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.8716 - val_loss: 0.4283\n",
            "Epoch 175/400\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.8663 - val_loss: 0.4272\n",
            "Epoch 176/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.8609 - val_loss: 0.4261\n",
            "Epoch 177/400\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.8556 - val_loss: 0.4250\n",
            "Epoch 178/400\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.8503 - val_loss: 0.4240\n",
            "Epoch 179/400\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.8451 - val_loss: 0.4231\n",
            "Epoch 180/400\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.8398 - val_loss: 0.4222\n",
            "Epoch 181/400\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.8346 - val_loss: 0.4213\n",
            "Epoch 182/400\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.8294 - val_loss: 0.4205\n",
            "Epoch 183/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.8242 - val_loss: 0.4197\n",
            "Epoch 184/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.8191 - val_loss: 0.4189\n",
            "Epoch 185/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.8140 - val_loss: 0.4181\n",
            "Epoch 186/400\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.8089 - val_loss: 0.4174\n",
            "Epoch 187/400\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.8038 - val_loss: 0.4166\n",
            "Epoch 188/400\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.7988 - val_loss: 0.4159\n",
            "Epoch 189/400\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.7938 - val_loss: 0.4151\n",
            "Epoch 190/400\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.7888 - val_loss: 0.4143\n",
            "Epoch 191/400\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.7839 - val_loss: 0.4136\n",
            "Epoch 192/400\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.7790 - val_loss: 0.4128\n",
            "Epoch 193/400\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.7741 - val_loss: 0.4120\n",
            "Epoch 194/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.7692 - val_loss: 0.4111\n",
            "Epoch 195/400\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.7644 - val_loss: 0.4102\n",
            "Epoch 196/400\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.7596 - val_loss: 0.4093\n",
            "Epoch 197/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.7549 - val_loss: 0.4084\n",
            "Epoch 198/400\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.7502 - val_loss: 0.4074\n",
            "Epoch 199/400\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.7455 - val_loss: 0.4063\n",
            "Epoch 200/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.7408 - val_loss: 0.4052\n",
            "Epoch 201/400\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.7362 - val_loss: 0.4040\n",
            "Epoch 202/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.7316 - val_loss: 0.4027\n",
            "Epoch 203/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.7270 - val_loss: 0.4014\n",
            "Epoch 204/400\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.7225 - val_loss: 0.4000\n",
            "Epoch 205/400\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.7180 - val_loss: 0.3985\n",
            "Epoch 206/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.7136 - val_loss: 0.3969\n",
            "Epoch 207/400\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.7092 - val_loss: 0.3952\n",
            "Epoch 208/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.7048 - val_loss: 0.3935\n",
            "Epoch 209/400\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.7004 - val_loss: 0.3916\n",
            "Epoch 210/400\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.6961 - val_loss: 0.3897\n",
            "Epoch 211/400\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.6919 - val_loss: 0.3876\n",
            "Epoch 212/400\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.6876 - val_loss: 0.3855\n",
            "Epoch 213/400\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.6834 - val_loss: 0.3832\n",
            "Epoch 214/400\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.6792 - val_loss: 0.3809\n",
            "Epoch 215/400\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.6751 - val_loss: 0.3785\n",
            "Epoch 216/400\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.6710 - val_loss: 0.3759\n",
            "Epoch 217/400\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.6669 - val_loss: 0.3733\n",
            "Epoch 218/400\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.6629 - val_loss: 0.3705\n",
            "Epoch 219/400\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.6589 - val_loss: 0.3676\n",
            "Epoch 220/400\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.6549 - val_loss: 0.3647\n",
            "Epoch 221/400\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.6510 - val_loss: 0.3616\n",
            "Epoch 222/400\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.6471 - val_loss: 0.3585\n",
            "Epoch 223/400\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.6432 - val_loss: 0.3553\n",
            "Epoch 224/400\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.6394 - val_loss: 0.3519\n",
            "Epoch 225/400\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.6356 - val_loss: 0.3485\n",
            "Epoch 226/400\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.6318 - val_loss: 0.3450\n",
            "Epoch 227/400\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6280 - val_loss: 0.3414\n",
            "Epoch 228/400\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6243 - val_loss: 0.3378\n",
            "Epoch 229/400\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.6206 - val_loss: 0.3340\n",
            "Epoch 230/400\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.6169 - val_loss: 0.3302\n",
            "Epoch 231/400\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.6133 - val_loss: 0.3264\n",
            "Epoch 232/400\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6097 - val_loss: 0.3224\n",
            "Epoch 233/400\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.6061 - val_loss: 0.3185\n",
            "Epoch 234/400\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.6025 - val_loss: 0.3144\n",
            "Epoch 235/400\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.5990 - val_loss: 0.3104\n",
            "Epoch 236/400\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5955 - val_loss: 0.3063\n",
            "Epoch 237/400\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5920 - val_loss: 0.3022\n",
            "Epoch 238/400\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5886 - val_loss: 0.2980\n",
            "Epoch 239/400\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5851 - val_loss: 0.2938\n",
            "Epoch 240/400\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5817 - val_loss: 0.2896\n",
            "Epoch 241/400\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.5783 - val_loss: 0.2855\n",
            "Epoch 242/400\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.5749 - val_loss: 0.2813\n",
            "Epoch 243/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.5716 - val_loss: 0.2771\n",
            "Epoch 244/400\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.5683 - val_loss: 0.2729\n",
            "Epoch 245/400\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.5649 - val_loss: 0.2688\n",
            "Epoch 246/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.5617 - val_loss: 0.2646\n",
            "Epoch 247/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.5584 - val_loss: 0.2605\n",
            "Epoch 248/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5551 - val_loss: 0.2565\n",
            "Epoch 249/400\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5519 - val_loss: 0.2524\n",
            "Epoch 250/400\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5487 - val_loss: 0.2485\n",
            "Epoch 251/400\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.5455 - val_loss: 0.2445\n",
            "Epoch 252/400\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.5424 - val_loss: 0.2407\n",
            "Epoch 253/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.5392 - val_loss: 0.2368\n",
            "Epoch 254/400\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.5361 - val_loss: 0.2331\n",
            "Epoch 255/400\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5330 - val_loss: 0.2294\n",
            "Epoch 256/400\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5299 - val_loss: 0.2258\n",
            "Epoch 257/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5268 - val_loss: 0.2222\n",
            "Epoch 258/400\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.5238 - val_loss: 0.2187\n",
            "Epoch 259/400\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.5208 - val_loss: 0.2153\n",
            "Epoch 260/400\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.5177 - val_loss: 0.2120\n",
            "Epoch 261/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.5148 - val_loss: 0.2087\n",
            "Epoch 262/400\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.5118 - val_loss: 0.2056\n",
            "Epoch 263/400\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.5089 - val_loss: 0.2025\n",
            "Epoch 264/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.5059 - val_loss: 0.1995\n",
            "Epoch 265/400\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.5031 - val_loss: 0.1965\n",
            "Epoch 266/400\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.5002 - val_loss: 0.1937\n",
            "Epoch 267/400\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.4973 - val_loss: 0.1909\n",
            "Epoch 268/400\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.4945 - val_loss: 0.1882\n",
            "Epoch 269/400\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.4917 - val_loss: 0.1856\n",
            "Epoch 270/400\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.4889 - val_loss: 0.1830\n",
            "Epoch 271/400\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.4862 - val_loss: 0.1806\n",
            "Epoch 272/400\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.4834 - val_loss: 0.1782\n",
            "Epoch 273/400\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.4807 - val_loss: 0.1758\n",
            "Epoch 274/400\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.4780 - val_loss: 0.1736\n",
            "Epoch 275/400\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.4754 - val_loss: 0.1714\n",
            "Epoch 276/400\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.4727 - val_loss: 0.1693\n",
            "Epoch 277/400\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.4701 - val_loss: 0.1672\n",
            "Epoch 278/400\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.4675 - val_loss: 0.1652\n",
            "Epoch 279/400\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.4650 - val_loss: 0.1633\n",
            "Epoch 280/400\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.4624 - val_loss: 0.1614\n",
            "Epoch 281/400\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.4599 - val_loss: 0.1596\n",
            "Epoch 282/400\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.4574 - val_loss: 0.1578\n",
            "Epoch 283/400\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.4549 - val_loss: 0.1561\n",
            "Epoch 284/400\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.4525 - val_loss: 0.1544\n",
            "Epoch 285/400\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.4501 - val_loss: 0.1528\n",
            "Epoch 286/400\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.4477 - val_loss: 0.1512\n",
            "Epoch 287/400\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.4454 - val_loss: 0.1497\n",
            "Epoch 288/400\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.4430 - val_loss: 0.1482\n",
            "Epoch 289/400\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.4407 - val_loss: 0.1468\n",
            "Epoch 290/400\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.4384 - val_loss: 0.1454\n",
            "Epoch 291/400\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.4362 - val_loss: 0.1441\n",
            "Epoch 292/400\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.4339 - val_loss: 0.1428\n",
            "Epoch 293/400\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.4317 - val_loss: 0.1415\n",
            "Epoch 294/400\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.4295 - val_loss: 0.1402\n",
            "Epoch 295/400\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.4274 - val_loss: 0.1390\n",
            "Epoch 296/400\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.4253 - val_loss: 0.1379\n",
            "Epoch 297/400\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.4232 - val_loss: 0.1368\n",
            "Epoch 298/400\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.4211 - val_loss: 0.1357\n",
            "Epoch 299/400\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.4190 - val_loss: 0.1346\n",
            "Epoch 300/400\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.4170 - val_loss: 0.1336\n",
            "Epoch 301/400\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.4150 - val_loss: 0.1326\n",
            "Epoch 302/400\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.4130 - val_loss: 0.1316\n",
            "Epoch 303/400\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.4110 - val_loss: 0.1306\n",
            "Epoch 304/400\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.4091 - val_loss: 0.1297\n",
            "Epoch 305/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.4072 - val_loss: 0.1288\n",
            "Epoch 306/400\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.4053 - val_loss: 0.1280\n",
            "Epoch 307/400\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.4035 - val_loss: 0.1271\n",
            "Epoch 308/400\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.4016 - val_loss: 0.1263\n",
            "Epoch 309/400\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.3998 - val_loss: 0.1255\n",
            "Epoch 310/400\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.3980 - val_loss: 0.1248\n",
            "Epoch 311/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.3962 - val_loss: 0.1240\n",
            "Epoch 312/400\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.3945 - val_loss: 0.1233\n",
            "Epoch 313/400\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.3928 - val_loss: 0.1226\n",
            "Epoch 314/400\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.3911 - val_loss: 0.1219\n",
            "Epoch 315/400\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.3894 - val_loss: 0.1213\n",
            "Epoch 316/400\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.3877 - val_loss: 0.1206\n",
            "Epoch 317/400\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.3861 - val_loss: 0.1200\n",
            "Epoch 318/400\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.3845 - val_loss: 0.1194\n",
            "Epoch 319/400\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.3829 - val_loss: 0.1188\n",
            "Epoch 320/400\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.3814 - val_loss: 0.1182\n",
            "Epoch 321/400\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.3798 - val_loss: 0.1177\n",
            "Epoch 322/400\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.3783 - val_loss: 0.1171\n",
            "Epoch 323/400\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.3768 - val_loss: 0.1166\n",
            "Epoch 324/400\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.3753 - val_loss: 0.1161\n",
            "Epoch 325/400\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.3738 - val_loss: 0.1156\n",
            "Epoch 326/400\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.3724 - val_loss: 0.1151\n",
            "Epoch 327/400\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.3710 - val_loss: 0.1146\n",
            "Epoch 328/400\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.3696 - val_loss: 0.1142\n",
            "Epoch 329/400\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.3682 - val_loss: 0.1137\n",
            "Epoch 330/400\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.3669 - val_loss: 0.1133\n",
            "Epoch 331/400\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.3655 - val_loss: 0.1129\n",
            "Epoch 332/400\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.3642 - val_loss: 0.1124\n",
            "Epoch 333/400\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.3629 - val_loss: 0.1120\n",
            "Epoch 334/400\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.3617 - val_loss: 0.1116\n",
            "Epoch 335/400\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.3604 - val_loss: 0.1113\n",
            "Epoch 336/400\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.3592 - val_loss: 0.1109\n",
            "Epoch 337/400\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.3580 - val_loss: 0.1105\n",
            "Epoch 338/400\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.3568 - val_loss: 0.1102\n",
            "Epoch 339/400\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.3556 - val_loss: 0.1098\n",
            "Epoch 340/400\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.3545 - val_loss: 0.1095\n",
            "Epoch 341/400\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.3534 - val_loss: 0.1092\n",
            "Epoch 342/400\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.3523 - val_loss: 0.1088\n",
            "Epoch 343/400\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.3512 - val_loss: 0.1085\n",
            "Epoch 344/400\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.3501 - val_loss: 0.1082\n",
            "Epoch 345/400\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.3491 - val_loss: 0.1079\n",
            "Epoch 346/400\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.3481 - val_loss: 0.1076\n",
            "Epoch 347/400\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.3471 - val_loss: 0.1073\n",
            "Epoch 348/400\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.3461 - val_loss: 0.1071\n",
            "Epoch 349/400\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.3451 - val_loss: 0.1068\n",
            "Epoch 350/400\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.3442 - val_loss: 0.1065\n",
            "Epoch 351/400\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.3432 - val_loss: 0.1063\n",
            "Epoch 352/400\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.3423 - val_loss: 0.1060\n",
            "Epoch 353/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.3414 - val_loss: 0.1058\n",
            "Epoch 354/400\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.3406 - val_loss: 0.1055\n",
            "Epoch 355/400\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.3397 - val_loss: 0.1053\n",
            "Epoch 356/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.3389 - val_loss: 0.1051\n",
            "Epoch 357/400\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.3381 - val_loss: 0.1048\n",
            "Epoch 358/400\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.3373 - val_loss: 0.1046\n",
            "Epoch 359/400\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.3365 - val_loss: 0.1044\n",
            "Epoch 360/400\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.3357 - val_loss: 0.1042\n",
            "Epoch 361/400\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.3350 - val_loss: 0.1040\n",
            "Epoch 362/400\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.3343 - val_loss: 0.1038\n",
            "Epoch 363/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.3336 - val_loss: 0.1036\n",
            "Epoch 364/400\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.3329 - val_loss: 0.1034\n",
            "Epoch 365/400\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.3322 - val_loss: 0.1033\n",
            "Epoch 366/400\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.3316 - val_loss: 0.1031\n",
            "Epoch 367/400\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.3309 - val_loss: 0.1029\n",
            "Epoch 368/400\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.3303 - val_loss: 0.1027\n",
            "Epoch 369/400\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.3297 - val_loss: 0.1026\n",
            "Epoch 370/400\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.3291 - val_loss: 0.1024\n",
            "Epoch 371/400\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.3286 - val_loss: 0.1023\n",
            "Epoch 372/400\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.3280 - val_loss: 0.1021\n",
            "Epoch 373/400\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.3275 - val_loss: 0.1020\n",
            "Epoch 374/400\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.3269 - val_loss: 0.1018\n",
            "Epoch 375/400\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.3264 - val_loss: 0.1017\n",
            "Epoch 376/400\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.3259 - val_loss: 0.1015\n",
            "Epoch 377/400\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.3255 - val_loss: 0.1014\n",
            "Epoch 378/400\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.3250 - val_loss: 0.1013\n",
            "Epoch 379/400\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.3245 - val_loss: 0.1011\n",
            "Epoch 380/400\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.3241 - val_loss: 0.1010\n",
            "Epoch 381/400\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.3237 - val_loss: 0.1009\n",
            "Epoch 382/400\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.3233 - val_loss: 0.1008\n",
            "Epoch 383/400\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.3229 - val_loss: 0.1007\n",
            "Epoch 384/400\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.3225 - val_loss: 0.1006\n",
            "Epoch 385/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.3221 - val_loss: 0.1005\n",
            "Epoch 386/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.3217 - val_loss: 0.1004\n",
            "Epoch 387/400\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.3214 - val_loss: 0.1003\n",
            "Epoch 388/400\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.3211 - val_loss: 0.1002\n",
            "Epoch 389/400\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.3207 - val_loss: 0.1001\n",
            "Epoch 390/400\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.3204 - val_loss: 0.1000\n",
            "Epoch 391/400\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.3201 - val_loss: 0.0999\n",
            "Epoch 392/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.3198 - val_loss: 0.0998\n",
            "Epoch 393/400\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.3195 - val_loss: 0.0997\n",
            "Epoch 394/400\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.3192 - val_loss: 0.0996\n",
            "Epoch 395/400\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.3190 - val_loss: 0.0995\n",
            "Epoch 396/400\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.3187 - val_loss: 0.0995\n",
            "Epoch 397/400\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.3185 - val_loss: 0.0994\n",
            "Epoch 398/400\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.3182 - val_loss: 0.0993\n",
            "Epoch 399/400\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.3180 - val_loss: 0.0993\n",
            "Epoch 400/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.3178 - val_loss: 0.0992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faed1d6e4d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1/400\n",
            "1/1 [==============================] - 1s 990ms/step - loss: 1.8868 - val_loss: 0.5498\n",
            "Epoch 2/400\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.8825 - val_loss: 0.5473\n",
            "Epoch 3/400\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 1.8783 - val_loss: 0.5448\n",
            "Epoch 4/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 1.8741 - val_loss: 0.5422\n",
            "Epoch 5/400\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.8700 - val_loss: 0.5397\n",
            "Epoch 6/400\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.8658 - val_loss: 0.5372\n",
            "Epoch 7/400\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 1.8617 - val_loss: 0.5347\n",
            "Epoch 8/400\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 1.8576 - val_loss: 0.5323\n",
            "Epoch 9/400\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.8536 - val_loss: 0.5298\n",
            "Epoch 10/400\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 1.8496 - val_loss: 0.5273\n",
            "Epoch 11/400\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.8456 - val_loss: 0.5249\n",
            "Epoch 12/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.8416 - val_loss: 0.5224\n",
            "Epoch 13/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.8376 - val_loss: 0.5199\n",
            "Epoch 14/400\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.8336 - val_loss: 0.5175\n",
            "Epoch 15/400\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 1.8297 - val_loss: 0.5150\n",
            "Epoch 16/400\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 1.8258 - val_loss: 0.5126\n",
            "Epoch 17/400\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 1.8219 - val_loss: 0.5102\n",
            "Epoch 18/400\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 1.8180 - val_loss: 0.5077\n",
            "Epoch 19/400\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 1.8141 - val_loss: 0.5053\n",
            "Epoch 20/400\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 1.8102 - val_loss: 0.5028\n",
            "Epoch 21/400\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 1.8063 - val_loss: 0.5004\n",
            "Epoch 22/400\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 1.8024 - val_loss: 0.4979\n",
            "Epoch 23/400\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 1.7985 - val_loss: 0.4955\n",
            "Epoch 24/400\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 1.7946 - val_loss: 0.4930\n",
            "Epoch 25/400\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 1.7907 - val_loss: 0.4906\n",
            "Epoch 26/400\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 1.7868 - val_loss: 0.4881\n",
            "Epoch 27/400\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 1.7829 - val_loss: 0.4856\n",
            "Epoch 28/400\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 1.7790 - val_loss: 0.4832\n",
            "Epoch 29/400\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 1.7751 - val_loss: 0.4807\n",
            "Epoch 30/400\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 1.7711 - val_loss: 0.4782\n",
            "Epoch 31/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 1.7672 - val_loss: 0.4757\n",
            "Epoch 32/400\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 1.7632 - val_loss: 0.4733\n",
            "Epoch 33/400\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 1.7593 - val_loss: 0.4708\n",
            "Epoch 34/400\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1.7553 - val_loss: 0.4683\n",
            "Epoch 35/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.7513 - val_loss: 0.4658\n",
            "Epoch 36/400\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 1.7472 - val_loss: 0.4633\n",
            "Epoch 37/400\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 1.7432 - val_loss: 0.4608\n",
            "Epoch 38/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 1.7391 - val_loss: 0.4583\n",
            "Epoch 39/400\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1.7350 - val_loss: 0.4558\n",
            "Epoch 40/400\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 1.7309 - val_loss: 0.4534\n",
            "Epoch 41/400\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 1.7268 - val_loss: 0.4509\n",
            "Epoch 42/400\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 1.7227 - val_loss: 0.4484\n",
            "Epoch 43/400\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 1.7185 - val_loss: 0.4459\n",
            "Epoch 44/400\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 1.7143 - val_loss: 0.4434\n",
            "Epoch 45/400\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 1.7101 - val_loss: 0.4409\n",
            "Epoch 46/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 1.7058 - val_loss: 0.4384\n",
            "Epoch 47/400\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 1.7015 - val_loss: 0.4359\n",
            "Epoch 48/400\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 1.6972 - val_loss: 0.4334\n",
            "Epoch 49/400\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 1.6929 - val_loss: 0.4309\n",
            "Epoch 50/400\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 1.6885 - val_loss: 0.4284\n",
            "Epoch 51/400\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 1.6841 - val_loss: 0.4259\n",
            "Epoch 52/400\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 1.6797 - val_loss: 0.4234\n",
            "Epoch 53/400\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 1.6753 - val_loss: 0.4209\n",
            "Epoch 54/400\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 1.6708 - val_loss: 0.4184\n",
            "Epoch 55/400\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 1.6663 - val_loss: 0.4159\n",
            "Epoch 56/400\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 1.6617 - val_loss: 0.4134\n",
            "Epoch 57/400\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 1.6571 - val_loss: 0.4109\n",
            "Epoch 58/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 1.6525 - val_loss: 0.4084\n",
            "Epoch 59/400\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 1.6479 - val_loss: 0.4059\n",
            "Epoch 60/400\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 1.6432 - val_loss: 0.4034\n",
            "Epoch 61/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 1.6385 - val_loss: 0.4009\n",
            "Epoch 62/400\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 1.6337 - val_loss: 0.3984\n",
            "Epoch 63/400\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 1.6289 - val_loss: 0.3959\n",
            "Epoch 64/400\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 1.6241 - val_loss: 0.3934\n",
            "Epoch 65/400\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 1.6192 - val_loss: 0.3909\n",
            "Epoch 66/400\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 1.6143 - val_loss: 0.3884\n",
            "Epoch 67/400\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 1.6094 - val_loss: 0.3859\n",
            "Epoch 68/400\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 1.6044 - val_loss: 0.3835\n",
            "Epoch 69/400\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 1.5994 - val_loss: 0.3810\n",
            "Epoch 70/400\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 1.5943 - val_loss: 0.3785\n",
            "Epoch 71/400\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 1.5892 - val_loss: 0.3760\n",
            "Epoch 72/400\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.5841 - val_loss: 0.3736\n",
            "Epoch 73/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 1.5789 - val_loss: 0.3711\n",
            "Epoch 74/400\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.5737 - val_loss: 0.3686\n",
            "Epoch 75/400\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1.5685 - val_loss: 0.3662\n",
            "Epoch 76/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.5632 - val_loss: 0.3637\n",
            "Epoch 77/400\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.5578 - val_loss: 0.3613\n",
            "Epoch 78/400\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 1.5524 - val_loss: 0.3588\n",
            "Epoch 79/400\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 1.5470 - val_loss: 0.3564\n",
            "Epoch 80/400\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 1.5415 - val_loss: 0.3540\n",
            "Epoch 81/400\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.5360 - val_loss: 0.3516\n",
            "Epoch 82/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.5304 - val_loss: 0.3492\n",
            "Epoch 83/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.5248 - val_loss: 0.3468\n",
            "Epoch 84/400\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 1.5191 - val_loss: 0.3444\n",
            "Epoch 85/400\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1.5134 - val_loss: 0.3420\n",
            "Epoch 86/400\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.5077 - val_loss: 0.3396\n",
            "Epoch 87/400\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.5018 - val_loss: 0.3373\n",
            "Epoch 88/400\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 1.4960 - val_loss: 0.3349\n",
            "Epoch 89/400\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.4901 - val_loss: 0.3326\n",
            "Epoch 90/400\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.4841 - val_loss: 0.3302\n",
            "Epoch 91/400\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 1.4781 - val_loss: 0.3279\n",
            "Epoch 92/400\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1.4720 - val_loss: 0.3256\n",
            "Epoch 93/400\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 1.4659 - val_loss: 0.3233\n",
            "Epoch 94/400\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.4598 - val_loss: 0.3211\n",
            "Epoch 95/400\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 1.4535 - val_loss: 0.3188\n",
            "Epoch 96/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 1.4473 - val_loss: 0.3165\n",
            "Epoch 97/400\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1.4409 - val_loss: 0.3143\n",
            "Epoch 98/400\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.4346 - val_loss: 0.3121\n",
            "Epoch 99/400\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 1.4281 - val_loss: 0.3099\n",
            "Epoch 100/400\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 1.4216 - val_loss: 0.3077\n",
            "Epoch 101/400\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1.4151 - val_loss: 0.3055\n",
            "Epoch 102/400\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.4085 - val_loss: 0.3034\n",
            "Epoch 103/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.4019 - val_loss: 0.3013\n",
            "Epoch 104/400\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1.3952 - val_loss: 0.2992\n",
            "Epoch 105/400\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.3884 - val_loss: 0.2971\n",
            "Epoch 106/400\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.3816 - val_loss: 0.2950\n",
            "Epoch 107/400\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 1.3748 - val_loss: 0.2930\n",
            "Epoch 108/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.3679 - val_loss: 0.2909\n",
            "Epoch 109/400\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.3609 - val_loss: 0.2889\n",
            "Epoch 110/400\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.3539 - val_loss: 0.2870\n",
            "Epoch 111/400\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.3469 - val_loss: 0.2850\n",
            "Epoch 112/400\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.3397 - val_loss: 0.2831\n",
            "Epoch 113/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.3326 - val_loss: 0.2812\n",
            "Epoch 114/400\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 1.3254 - val_loss: 0.2793\n",
            "Epoch 115/400\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.3181 - val_loss: 0.2775\n",
            "Epoch 116/400\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1.3108 - val_loss: 0.2757\n",
            "Epoch 117/400\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1.3034 - val_loss: 0.2739\n",
            "Epoch 118/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.2960 - val_loss: 0.2722\n",
            "Epoch 119/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 1.2886 - val_loss: 0.2705\n",
            "Epoch 120/400\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 1.2811 - val_loss: 0.2688\n",
            "Epoch 121/400\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.2735 - val_loss: 0.2672\n",
            "Epoch 122/400\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 1.2659 - val_loss: 0.2656\n",
            "Epoch 123/400\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.2583 - val_loss: 0.2640\n",
            "Epoch 124/400\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 1.2506 - val_loss: 0.2625\n",
            "Epoch 125/400\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 1.2429 - val_loss: 0.2610\n",
            "Epoch 126/400\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 1.2351 - val_loss: 0.2596\n",
            "Epoch 127/400\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1.2272 - val_loss: 0.2582\n",
            "Epoch 128/400\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.2194 - val_loss: 0.2568\n",
            "Epoch 129/400\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.2115 - val_loss: 0.2555\n",
            "Epoch 130/400\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 1.2035 - val_loss: 0.2542\n",
            "Epoch 131/400\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 1.1955 - val_loss: 0.2530\n",
            "Epoch 132/400\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.1874 - val_loss: 0.2518\n",
            "Epoch 133/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 1.1794 - val_loss: 0.2507\n",
            "Epoch 134/400\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1.1712 - val_loss: 0.2496\n",
            "Epoch 135/400\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 1.1630 - val_loss: 0.2486\n",
            "Epoch 136/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.1548 - val_loss: 0.2476\n",
            "Epoch 137/400\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.1465 - val_loss: 0.2467\n",
            "Epoch 138/400\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1.1382 - val_loss: 0.2458\n",
            "Epoch 139/400\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 1.1298 - val_loss: 0.2450\n",
            "Epoch 140/400\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1.1214 - val_loss: 0.2443\n",
            "Epoch 141/400\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 1.1129 - val_loss: 0.2436\n",
            "Epoch 142/400\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.1044 - val_loss: 0.2429\n",
            "Epoch 143/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.0958 - val_loss: 0.2423\n",
            "Epoch 144/400\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.0872 - val_loss: 0.2418\n",
            "Epoch 145/400\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 1.0785 - val_loss: 0.2414\n",
            "Epoch 146/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.0697 - val_loss: 0.2410\n",
            "Epoch 147/400\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1.0609 - val_loss: 0.2407\n",
            "Epoch 148/400\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.0521 - val_loss: 0.2404\n",
            "Epoch 149/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.0431 - val_loss: 0.2402\n",
            "Epoch 150/400\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.0341 - val_loss: 0.2401\n",
            "Epoch 151/400\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 1.0250 - val_loss: 0.2401\n",
            "Epoch 152/400\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.0159 - val_loss: 0.2401\n",
            "Epoch 153/400\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1.0067 - val_loss: 0.2402\n",
            "Epoch 154/400\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.9974 - val_loss: 0.2404\n",
            "Epoch 155/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.9881 - val_loss: 0.2407\n",
            "Epoch 156/400\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.9787 - val_loss: 0.2410\n",
            "Epoch 157/400\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.9692 - val_loss: 0.2414\n",
            "Epoch 158/400\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.9596 - val_loss: 0.2419\n",
            "Epoch 159/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.9499 - val_loss: 0.2425\n",
            "Epoch 160/400\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.9402 - val_loss: 0.2432\n",
            "Epoch 161/400\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.9304 - val_loss: 0.2440\n",
            "Epoch 162/400\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.9205 - val_loss: 0.2448\n",
            "Epoch 163/400\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.9106 - val_loss: 0.2457\n",
            "Epoch 164/400\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.9006 - val_loss: 0.2468\n",
            "Epoch 165/400\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.8905 - val_loss: 0.2479\n",
            "Epoch 166/400\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.8804 - val_loss: 0.2491\n",
            "Epoch 167/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.8702 - val_loss: 0.2504\n",
            "Epoch 168/400\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.8599 - val_loss: 0.2518\n",
            "Epoch 169/400\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.8497 - val_loss: 0.2532\n",
            "Epoch 170/400\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.8393 - val_loss: 0.2548\n",
            "Epoch 171/400\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.8290 - val_loss: 0.2564\n",
            "Epoch 172/400\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.8187 - val_loss: 0.2582\n",
            "Epoch 173/400\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.8084 - val_loss: 0.2600\n",
            "Epoch 174/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.7980 - val_loss: 0.2619\n",
            "Epoch 175/400\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.7878 - val_loss: 0.2639\n",
            "Epoch 176/400\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.7775 - val_loss: 0.2660\n",
            "Epoch 177/400\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.7674 - val_loss: 0.2681\n",
            "Epoch 178/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.7574 - val_loss: 0.2703\n",
            "Epoch 179/400\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.7474 - val_loss: 0.2725\n",
            "Epoch 180/400\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.7377 - val_loss: 0.2748\n",
            "Epoch 181/400\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.7280 - val_loss: 0.2770\n",
            "Epoch 182/400\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.7186 - val_loss: 0.2794\n",
            "Epoch 183/400\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.7095 - val_loss: 0.2817\n",
            "Epoch 184/400\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.7005 - val_loss: 0.2839\n",
            "Epoch 185/400\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.6919 - val_loss: 0.2862\n",
            "Epoch 186/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6836 - val_loss: 0.2883\n",
            "Epoch 187/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6756 - val_loss: 0.2904\n",
            "Epoch 188/400\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.6680 - val_loss: 0.2924\n",
            "Epoch 189/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6608 - val_loss: 0.2941\n",
            "Epoch 190/400\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.6540 - val_loss: 0.2957\n",
            "Epoch 191/400\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6477 - val_loss: 0.2971\n",
            "Epoch 192/400\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6417 - val_loss: 0.2982\n",
            "Epoch 193/400\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6362 - val_loss: 0.2989\n",
            "Epoch 194/400\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6312 - val_loss: 0.2994\n",
            "Epoch 195/400\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.6265 - val_loss: 0.2994\n",
            "Epoch 196/400\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.6223 - val_loss: 0.2990\n",
            "Epoch 197/400\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6185 - val_loss: 0.2982\n",
            "Epoch 198/400\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6150 - val_loss: 0.2969\n",
            "Epoch 199/400\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6118 - val_loss: 0.2951\n",
            "Epoch 200/400\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6089 - val_loss: 0.2928\n",
            "Epoch 201/400\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6062 - val_loss: 0.2901\n",
            "Epoch 202/400\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.6037 - val_loss: 0.2868\n",
            "Epoch 203/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6013 - val_loss: 0.2832\n",
            "Epoch 204/400\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5990 - val_loss: 0.2791\n",
            "Epoch 205/400\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.5968 - val_loss: 0.2746\n",
            "Epoch 206/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.5946 - val_loss: 0.2698\n",
            "Epoch 207/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.5925 - val_loss: 0.2647\n",
            "Epoch 208/400\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.5903 - val_loss: 0.2594\n",
            "Epoch 209/400\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.5881 - val_loss: 0.2539\n",
            "Epoch 210/400\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.5859 - val_loss: 0.2482\n",
            "Epoch 211/400\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.5837 - val_loss: 0.2424\n",
            "Epoch 212/400\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.5815 - val_loss: 0.2366\n",
            "Epoch 213/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.5793 - val_loss: 0.2308\n",
            "Epoch 214/400\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5771 - val_loss: 0.2250\n",
            "Epoch 215/400\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.5750 - val_loss: 0.2193\n",
            "Epoch 216/400\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5729 - val_loss: 0.2137\n",
            "Epoch 217/400\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5708 - val_loss: 0.2082\n",
            "Epoch 218/400\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5688 - val_loss: 0.2029\n",
            "Epoch 219/400\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5669 - val_loss: 0.1977\n",
            "Epoch 220/400\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5651 - val_loss: 0.1927\n",
            "Epoch 221/400\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.5633 - val_loss: 0.1878\n",
            "Epoch 222/400\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5616 - val_loss: 0.1832\n",
            "Epoch 223/400\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.5600 - val_loss: 0.1788\n",
            "Epoch 224/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.5585 - val_loss: 0.1745\n",
            "Epoch 225/400\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5570 - val_loss: 0.1705\n",
            "Epoch 226/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.5556 - val_loss: 0.1666\n",
            "Epoch 227/400\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5542 - val_loss: 0.1629\n",
            "Epoch 228/400\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.5529 - val_loss: 0.1595\n",
            "Epoch 229/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5516 - val_loss: 0.1561\n",
            "Epoch 230/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.5503 - val_loss: 0.1530\n",
            "Epoch 231/400\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.5491 - val_loss: 0.1500\n",
            "Epoch 232/400\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.5479 - val_loss: 0.1471\n",
            "Epoch 233/400\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.5467 - val_loss: 0.1444\n",
            "Epoch 234/400\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5455 - val_loss: 0.1418\n",
            "Epoch 235/400\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5444 - val_loss: 0.1393\n",
            "Epoch 236/400\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5433 - val_loss: 0.1369\n",
            "Epoch 237/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.5422 - val_loss: 0.1346\n",
            "Epoch 238/400\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5411 - val_loss: 0.1324\n",
            "Epoch 239/400\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5400 - val_loss: 0.1303\n",
            "Epoch 240/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.5390 - val_loss: 0.1282\n",
            "Epoch 241/400\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5380 - val_loss: 0.1262\n",
            "Epoch 242/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.5370 - val_loss: 0.1243\n",
            "Epoch 243/400\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5360 - val_loss: 0.1224\n",
            "Epoch 244/400\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5351 - val_loss: 0.1206\n",
            "Epoch 245/400\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.5341 - val_loss: 0.1188\n",
            "Epoch 246/400\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5332 - val_loss: 0.1170\n",
            "Epoch 247/400\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.5323 - val_loss: 0.1153\n",
            "Epoch 248/400\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5315 - val_loss: 0.1136\n",
            "Epoch 249/400\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.5306 - val_loss: 0.1119\n",
            "Epoch 250/400\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5298 - val_loss: 0.1102\n",
            "Epoch 251/400\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.5290 - val_loss: 0.1086\n",
            "Epoch 252/400\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.5282 - val_loss: 0.1070\n",
            "Epoch 253/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.5275 - val_loss: 0.1054\n",
            "Epoch 254/400\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5267 - val_loss: 0.1038\n",
            "Epoch 255/400\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5260 - val_loss: 0.1022\n",
            "Epoch 256/400\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5253 - val_loss: 0.1007\n",
            "Epoch 257/400\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5246 - val_loss: 0.0991\n",
            "Epoch 258/400\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5239 - val_loss: 0.0976\n",
            "Epoch 259/400\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.5232 - val_loss: 0.0962\n",
            "Epoch 260/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.5226 - val_loss: 0.0947\n",
            "Epoch 261/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.5219 - val_loss: 0.0933\n",
            "Epoch 262/400\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5213 - val_loss: 0.0919\n",
            "Epoch 263/400\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5207 - val_loss: 0.0905\n",
            "Epoch 264/400\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.5201 - val_loss: 0.0892\n",
            "Epoch 265/400\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.5195 - val_loss: 0.0879\n",
            "Epoch 266/400\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.5189 - val_loss: 0.0866\n",
            "Epoch 267/400\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.5183 - val_loss: 0.0854\n",
            "Epoch 268/400\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5178 - val_loss: 0.0841\n",
            "Epoch 269/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.5172 - val_loss: 0.0830\n",
            "Epoch 270/400\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5167 - val_loss: 0.0818\n",
            "Epoch 271/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.5162 - val_loss: 0.0807\n",
            "Epoch 272/400\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.5157 - val_loss: 0.0796\n",
            "Epoch 273/400\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5152 - val_loss: 0.0786\n",
            "Epoch 274/400\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.5147 - val_loss: 0.0775\n",
            "Epoch 275/400\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.5142 - val_loss: 0.0765\n",
            "Epoch 276/400\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.5138 - val_loss: 0.0755\n",
            "Epoch 277/400\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5133 - val_loss: 0.0746\n",
            "Epoch 278/400\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5129 - val_loss: 0.0737\n",
            "Epoch 279/400\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5124 - val_loss: 0.0728\n",
            "Epoch 280/400\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5120 - val_loss: 0.0719\n",
            "Epoch 281/400\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.5116 - val_loss: 0.0710\n",
            "Epoch 282/400\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.5112 - val_loss: 0.0702\n",
            "Epoch 283/400\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5108 - val_loss: 0.0694\n",
            "Epoch 284/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.5104 - val_loss: 0.0686\n",
            "Epoch 285/400\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.5100 - val_loss: 0.0678\n",
            "Epoch 286/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5096 - val_loss: 0.0670\n",
            "Epoch 287/400\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.5092 - val_loss: 0.0663\n",
            "Epoch 288/400\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.5089 - val_loss: 0.0655\n",
            "Epoch 289/400\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.5085 - val_loss: 0.0648\n",
            "Epoch 290/400\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.5082 - val_loss: 0.0641\n",
            "Epoch 291/400\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.5078 - val_loss: 0.0634\n",
            "Epoch 292/400\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.5075 - val_loss: 0.0627\n",
            "Epoch 293/400\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.5072 - val_loss: 0.0620\n",
            "Epoch 294/400\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5069 - val_loss: 0.0614\n",
            "Epoch 295/400\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.5065 - val_loss: 0.0607\n",
            "Epoch 296/400\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5062 - val_loss: 0.0601\n",
            "Epoch 297/400\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.5059 - val_loss: 0.0595\n",
            "Epoch 298/400\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.5057 - val_loss: 0.0589\n",
            "Epoch 299/400\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.5054 - val_loss: 0.0583\n",
            "Epoch 300/400\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.5051 - val_loss: 0.0577\n",
            "Epoch 301/400\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5048 - val_loss: 0.0571\n",
            "Epoch 302/400\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.5045 - val_loss: 0.0566\n",
            "Epoch 303/400\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.5043 - val_loss: 0.0560\n",
            "Epoch 304/400\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.5040 - val_loss: 0.0555\n",
            "Epoch 305/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5038 - val_loss: 0.0549\n",
            "Epoch 306/400\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5035 - val_loss: 0.0544\n",
            "Epoch 307/400\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.5033 - val_loss: 0.0539\n",
            "Epoch 308/400\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.5031 - val_loss: 0.0534\n",
            "Epoch 309/400\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5028 - val_loss: 0.0530\n",
            "Epoch 310/400\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.5026 - val_loss: 0.0525\n",
            "Epoch 311/400\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.5024 - val_loss: 0.0520\n",
            "Epoch 312/400\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.5022 - val_loss: 0.0516\n",
            "Epoch 313/400\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5020 - val_loss: 0.0511\n",
            "Epoch 314/400\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 0.5018 - val_loss: 0.0507\n",
            "Epoch 315/400\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.5016 - val_loss: 0.0503\n",
            "Epoch 316/400\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.5014 - val_loss: 0.0499\n",
            "Epoch 317/400\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.5012 - val_loss: 0.0495\n",
            "Epoch 318/400\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.5010 - val_loss: 0.0491\n",
            "Epoch 319/400\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.5008 - val_loss: 0.0487\n",
            "Epoch 320/400\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.5006 - val_loss: 0.0483\n",
            "Epoch 321/400\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.5004 - val_loss: 0.0479\n",
            "Epoch 322/400\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.5003 - val_loss: 0.0476\n",
            "Epoch 323/400\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.5001 - val_loss: 0.0472\n",
            "Epoch 324/400\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.4999 - val_loss: 0.0469\n",
            "Epoch 325/400\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.4998 - val_loss: 0.0465\n",
            "Epoch 326/400\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.4996 - val_loss: 0.0462\n",
            "Epoch 327/400\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.4995 - val_loss: 0.0458\n",
            "Epoch 328/400\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.4993 - val_loss: 0.0455\n",
            "Epoch 329/400\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.4992 - val_loss: 0.0452\n",
            "Epoch 330/400\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.4990 - val_loss: 0.0449\n",
            "Epoch 331/400\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.4989 - val_loss: 0.0446\n",
            "Epoch 332/400\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.4988 - val_loss: 0.0443\n",
            "Epoch 333/400\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 0.4986 - val_loss: 0.0440\n",
            "Epoch 334/400\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.4985 - val_loss: 0.0437\n",
            "Epoch 335/400\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.4984 - val_loss: 0.0434\n",
            "Epoch 336/400\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.4982 - val_loss: 0.0431\n",
            "Epoch 337/400\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.4981 - val_loss: 0.0429\n",
            "Epoch 338/400\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.4980 - val_loss: 0.0426\n",
            "Epoch 339/400\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.4979 - val_loss: 0.0423\n",
            "Epoch 340/400\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.4978 - val_loss: 0.0421\n",
            "Epoch 341/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.4976 - val_loss: 0.0418\n",
            "Epoch 342/400\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.4975 - val_loss: 0.0416\n",
            "Epoch 343/400\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.4974 - val_loss: 0.0413\n",
            "Epoch 344/400\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.4973 - val_loss: 0.0411\n",
            "Epoch 345/400\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.4972 - val_loss: 0.0409\n",
            "Epoch 346/400\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.4971 - val_loss: 0.0406\n",
            "Epoch 347/400\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.4970 - val_loss: 0.0404\n",
            "Epoch 348/400\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.4969 - val_loss: 0.0402\n",
            "Epoch 349/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.4968 - val_loss: 0.0400\n",
            "Epoch 350/400\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.4967 - val_loss: 0.0398\n",
            "Epoch 351/400\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.4966 - val_loss: 0.0395\n",
            "Epoch 352/400\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.4966 - val_loss: 0.0393\n",
            "Epoch 353/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.4965 - val_loss: 0.0391\n",
            "Epoch 354/400\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.4964 - val_loss: 0.0389\n",
            "Epoch 355/400\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.4963 - val_loss: 0.0387\n",
            "Epoch 356/400\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.4962 - val_loss: 0.0386\n",
            "Epoch 357/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.4961 - val_loss: 0.0384\n",
            "Epoch 358/400\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.4961 - val_loss: 0.0382\n",
            "Epoch 359/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.4960 - val_loss: 0.0380\n",
            "Epoch 360/400\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.4959 - val_loss: 0.0378\n",
            "Epoch 361/400\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.4958 - val_loss: 0.0377\n",
            "Epoch 362/400\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.4958 - val_loss: 0.0375\n",
            "Epoch 363/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.4957 - val_loss: 0.0373\n",
            "Epoch 364/400\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.4956 - val_loss: 0.0372\n",
            "Epoch 365/400\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.4956 - val_loss: 0.0370\n",
            "Epoch 366/400\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.4955 - val_loss: 0.0368\n",
            "Epoch 367/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.4954 - val_loss: 0.0367\n",
            "Epoch 368/400\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.4954 - val_loss: 0.0365\n",
            "Epoch 369/400\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.4953 - val_loss: 0.0364\n",
            "Epoch 370/400\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.4952 - val_loss: 0.0362\n",
            "Epoch 371/400\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.4952 - val_loss: 0.0361\n",
            "Epoch 372/400\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.4951 - val_loss: 0.0359\n",
            "Epoch 373/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.4951 - val_loss: 0.0358\n",
            "Epoch 374/400\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.4950 - val_loss: 0.0357\n",
            "Epoch 375/400\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.4950 - val_loss: 0.0355\n",
            "Epoch 376/400\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.4949 - val_loss: 0.0354\n",
            "Epoch 377/400\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.4949 - val_loss: 0.0353\n",
            "Epoch 378/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.4948 - val_loss: 0.0351\n",
            "Epoch 379/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.4948 - val_loss: 0.0350\n",
            "Epoch 380/400\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.4947 - val_loss: 0.0349\n",
            "Epoch 381/400\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.4947 - val_loss: 0.0348\n",
            "Epoch 382/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.4946 - val_loss: 0.0346\n",
            "Epoch 383/400\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.4946 - val_loss: 0.0345\n",
            "Epoch 384/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.4945 - val_loss: 0.0344\n",
            "Epoch 385/400\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.4945 - val_loss: 0.0343\n",
            "Epoch 386/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.4944 - val_loss: 0.0342\n",
            "Epoch 387/400\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.4944 - val_loss: 0.0341\n",
            "Epoch 388/400\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.4943 - val_loss: 0.0339\n",
            "Epoch 389/400\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.4943 - val_loss: 0.0338\n",
            "Epoch 390/400\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.4943 - val_loss: 0.0337\n",
            "Epoch 391/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.4942 - val_loss: 0.0336\n",
            "Epoch 392/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.4942 - val_loss: 0.0335\n",
            "Epoch 393/400\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.4941 - val_loss: 0.0334\n",
            "Epoch 394/400\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.4941 - val_loss: 0.0333\n",
            "Epoch 395/400\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.4941 - val_loss: 0.0332\n",
            "Epoch 396/400\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.4940 - val_loss: 0.0331\n",
            "Epoch 397/400\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.4940 - val_loss: 0.0330\n",
            "Epoch 398/400\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.4939 - val_loss: 0.0329\n",
            "Epoch 399/400\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.4939 - val_loss: 0.0329\n",
            "Epoch 400/400\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.4939 - val_loss: 0.0328\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faed1b9e710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 8ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_time = sum(etime)\n",
        "total_loss = sum(loss)/len(loss)\n",
        "print(f\"Execution time per radius: {etime} seconds\")\n",
        "print(f\"Test loss per radius: {loss}\")\n",
        "print(f\"Total Execution time: {training_time} seconds\")\n",
        "print(f\"Average Test loss: {total_loss}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VOug8qdI-gc",
        "outputId": "e1076ccf-c754-4de4-efec-93adea5831b4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution time per radius: [28.16491460800171, 41.786205768585205, 24.55959725379944, 41.65004229545593, 41.805570125579834, 21.763712167739868] seconds\n",
            "Test loss per radius: [0.12299644947052002, 0.14230895042419434, 0.16672468185424805, 0.35471585392951965, 0.5130527019500732, 0.195460245013237]\n",
            "Total Execution time: 199.730042219162 seconds\n",
            "Average Test loss: 0.24920981377363205\n"
          ]
        }
      ]
    }
  ]
}